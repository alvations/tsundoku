{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Library/Frameworks/Python.framework/Versions/3.6/bin/python3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Optional]: If you're using a Mac/Linux, you can check your environment with these commands:\n",
    "\n",
    "```\n",
    "!which pip3\n",
    "!which python3\n",
    "!ls -lah /usr/local/bin/python3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (19.3.1)\n",
      "Requirement already satisfied: torch==1.2.0 in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (1.2.0)\n",
      "Requirement already satisfied: numpy in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from torch==1.2.0) (1.17.2)\n",
      "Requirement already satisfied: seaborn in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (0.9.0)\n",
      "Requirement already satisfied: pandas>=0.15.2 in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from seaborn) (0.25.1)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from seaborn) (1.2.1)\n",
      "Requirement already satisfied: matplotlib>=1.4.3 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from seaborn) (3.1.1)\n",
      "Requirement already satisfied: numpy>=1.9.3 in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from seaborn) (1.17.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from pandas>=0.15.2->seaborn) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from pandas>=0.15.2->seaborn) (2019.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (2.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from python-dateutil>=2.6.1->pandas>=0.15.2->seaborn) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn) (41.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -U pip\n",
    "!pip3 install torch==1.2.0\n",
    "!pip3 install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython candies...\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style> table {float:left} </style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style> table {float:left} </style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron\n",
    "=====\n",
    "\n",
    "**Perceptron** algorithm is a:\n",
    "\n",
    "> \"*system that depends on **probabilistic** rather than deterministic principles for its operation, gains its reliability from the **properties of statistical measurements obtain from a large population of elements***\"\n",
    "> \\- Frank Rosenblatt (1957)\n",
    "\n",
    "Then the news:\n",
    "\n",
    "> \"*[Perceptron is an] **embryo of an electronic computer** that [the Navy] expects will be **able to walk, talk, see, write, reproduce itself and be conscious of its existence.***\"\n",
    "> \\- The New York Times (1958)\n",
    "\n",
    "News quote cite from Olazaran (1996) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron in Bullets\n",
    "----\n",
    "\n",
    " - Perceptron learns to classify any linearly separable set of inputs. \n",
    " - Some nice graphics for perceptron with Go https://appliedgo.net/perceptron/  \n",
    "\n",
    "If you've got some spare time: \n",
    "\n",
    " - There's a whole book just on perceptron: https://mitpress.mit.edu/books/perceptrons\n",
    " - For watercooler gossips on perceptron in the early days, read [Olazaran (1996)](https://pdfs.semanticscholar.org/f3b6/e5ef511b471ff508959f660c94036b434277.pdf?_ga=2.57343906.929185581.1517539221-1505787125.1517539221)\n",
    " \n",
    " \n",
    "Perceptron in Math\n",
    "----\n",
    "\n",
    "Given a set of inputs $x$, the perceptron \n",
    "\n",
    " - learns $w$ vector to map the inputs to a real-value output between $[0,1]$\n",
    " - through the summation of the dot product of the $w·x$ with a transformation function\n",
    " \n",
    " \n",
    "Perceptron in Picture\n",
    "----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://ibin.co/4TyMU8AdpV4J.png\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Image(url=\"perceptron.png\", width=500)\n",
    "Image(url=\"https://ibin.co/4TyMU8AdpV4J.png\", width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(**Note:** Usually, we use $x_1$ as the bias and fix the input to 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron as a Workflow Diagram\n",
    "----\n",
    "\n",
    "If you're familiar with [mermaid flowchart](https://mermaidjs.github.io)\n",
    "\n",
    "```\n",
    ".. mermaid::\n",
    "\n",
    "    graph LR\n",
    "       subgraph Input\n",
    "          x_1\n",
    "          x_i \n",
    "          x_n\n",
    "       end\n",
    "       subgraph Perceptron\n",
    "            n1((s)) --> n2((\"f(s)\"))\n",
    "        end\n",
    "        x_1 --> |w_1| n1\n",
    "        x_i --> |w_i| n1\n",
    "        x_n --> |w_n| n1\n",
    "        n2 --> y[\"[0,1]\"]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://svgshare.com/i/AbJ.svg\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Image(url=\"perceptron-mermaid.svg\", width=500)\n",
    "Image(url=\"https://svgshare.com/i/AbJ.svg\", width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization Process\n",
    "====\n",
    "\n",
    "To learn the weights, $w$, we use an **optimizer** to find the best-fit (optimal) values for $w$ such that the inputs correct maps to the outputs.\n",
    "\n",
    "Typically, process performs the following 4 steps iteratively.\n",
    "\n",
    "### **Initialization**\n",
    "\n",
    " - **Step 1**: Initialize weights vector\n",
    " \n",
    "### **Forward Propagation**\n",
    "\n",
    " \n",
    " - **Step 2a**: Multiply the weights vector with the inputs, sum the products, i.e. `s`\n",
    " - **Step 2b**: Put the sum through the sigmoid, i.e. `f()`\n",
    " \n",
    "### **Back Propagation**\n",
    " \n",
    " \n",
    " - **Step 3a**: Compute the errors, i.e. difference between expected output and predictions\n",
    " - **Step 3b**: Multiply the error with the **derivatives** to get the delta\n",
    " - **Step 3c**: Multiply the delta vector with the inputs, sum the product\n",
    " \n",
    "### **Optimizer takes a step**\n",
    "\n",
    " - **Step 4**: Multiply the learning rate with the output of Step 3c.\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x): # Returns values that sums to one.\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(sx): \n",
    "    # See https://math.stackexchange.com/a/1225116\n",
    "    # Hint: let sx = sigmoid(x)\n",
    "    return ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92414182, 0.57932425, 0.19466158])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(np.array([2.5, 0.32, -1.42]))             # [out]: array([0.92414182, 0.57932425, 0.19466158])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.75  ,  0.2176, -3.4364])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_derivative(np.array([2.5, 0.32, -1.42]))  # [out]: array([0.07010372, 0.24370766, 0.15676845])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(predicted, truth):\n",
    "    return np.abs(truth - predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1, 0.2, 0.2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold = np.array([0.5, 1.2, 9.8])\n",
    "pred = np.array([0.6, 1.0, 10.0])\n",
    "cost(pred, gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.8,  2.8, 89.2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold = np.array([0.5, 1.2, 9.8])\n",
    "pred = np.array([9.3, 4.0, 99.0])\n",
    "cost(pred, gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representing OR Boolean\n",
    "---\n",
    "\n",
    "Lets consider the problem of the OR boolean and apply the perceptron with simple gradient descent. \n",
    "\n",
    "| x2 | x3 | y | \n",
    "|:--:|:--:|:--:|\n",
    "| 0 | 0 | 0 |\n",
    "| 0 | 1 | 1 | \n",
    "| 1 | 0 | 1 | \n",
    "| 1 | 1 | 1 | \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = or_input = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "Y = or_output = np.array([[0,1,1,1]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "or_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "or_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the shape of the weight vector.\n",
    "num_data, input_dim = ???\n",
    "# Define the shape of the output vector. \n",
    "output_dim = len(or_output.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs\n",
      "======\n",
      "no. of rows = 4\n",
      "no. of cols = 2\n",
      "\n",
      "\n",
      "Outputs\n",
      "=======\n",
      "no. of cols = 1\n"
     ]
    }
   ],
   "source": [
    "print('Inputs\\n======')\n",
    "print('no. of rows =', num_data) \n",
    "print('no. of cols =', input_dim)\n",
    "print('\\n')\n",
    "print('Outputs\\n=======')\n",
    "print('no. of cols =', output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5488135 ],\n",
       "       [0.71518937]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize weights between the input layers and the perceptron\n",
    "W = np.random.random((input_dim, output_dim))\n",
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2a: Multiply the weights vector with the inputs, sum the products\n",
    "====\n",
    "\n",
    "To get the output of step 2a, \n",
    "\n",
    " - Itrate through each row of the data, `X`\n",
    " - For each column in each row, find the product of the value and the respective weights\n",
    " - For each row, compute the sum of the products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.        ]\n",
      " [0.71518937]\n",
      " [0.5488135 ]\n",
      " [1.26400287]]\n"
     ]
    }
   ],
   "source": [
    "# If we write it imperatively:\n",
    "summation = []\n",
    "for row in X:\n",
    "    sum_wx = 0\n",
    "    for feature, weight in zip(row, W):\n",
    "        sum_wx += ???\n",
    "    summation.append(???)\n",
    "print(np.array(summation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.71518937],\n",
       "       [0.5488135 ],\n",
       "       [1.26400287]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we vectorize the process and use numpy.\n",
    "np.dot(X, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Single-Layer Model\n",
    "====\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10000 # No. of times to iterate.\n",
    "learning_rate = 0.03 # How large a step to take per iteration.\n",
    "\n",
    "# Lets standardize and call our inputs X and outputs Y\n",
    "X = or_input\n",
    "Y = or_output\n",
    "\n",
    "for _ in range(num_epochs):\n",
    "    layer0 = X\n",
    "\n",
    "    # Step 2a: Multiply the weights vector with the inputs, sum the products, i.e. s\n",
    "    # Step 2b: Put the sum through the sigmoid, i.e. f()\n",
    "    # Inside the perceptron, Step 2. \n",
    "    layer1 = sigmoid(np.dot(X, W))\n",
    "\n",
    "    # Back propagation.\n",
    "    # Step 3a: Compute the errors, i.e. difference between expected output and predictions\n",
    "    # How much did we miss?\n",
    "    layer1_error = cost(layer1, Y)\n",
    "\n",
    "    # Step 3b: Multiply the error with the derivatives to get the delta\n",
    "    # multiply how much we missed by the slope of the sigmoid at the values in layer1\n",
    "    layer1_delta = layer1_error * sigmoid_derivative(layer1)\n",
    "\n",
    "    # Step 3c: Multiply the delta vector with the inputs, sum the product (use np.dot)\n",
    "    # Step 4: Multiply the learning rate with the output of Step 3c.\n",
    "    W +=  learning_rate * np.dot(layer0.T, layer1_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       ],\n",
       "       [0.95643415],\n",
       "       [0.95623017],\n",
       "       [0.99791935]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expected output.\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [1], [1], [1]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On the training data\n",
    "[[int(prediction > 0.5)] for prediction in layer1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try the XOR Boolean\n",
    "---\n",
    "\n",
    "Lets consider the problem of the OR boolean and apply the perceptron with simple gradient descent. \n",
    "\n",
    "| x2 | x3 | y | \n",
    "|:--:|:--:|:--:|\n",
    "| 0 | 0 | 0 |\n",
    "| 0 | 1 | 1 | \n",
    "| 1 | 0 | 1 | \n",
    "| 1 | 1 | 0 | \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = xor_input = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "Y = xor_output = np.array([[0,1,1,0]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xor_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xor_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10000 # No. of times to iterate.\n",
    "learning_rate = 0.003 # How large a step to take per iteration.\n",
    "\n",
    "# Lets drop the last row of data and use that as unseen test.\n",
    "X = xor_input\n",
    "Y = xor_output\n",
    "\n",
    "# Define the shape of the weight vector.\n",
    "num_data, input_dim = ???\n",
    "# Define the shape of the output vector. \n",
    "output_dim = len(Y.T)\n",
    "# Initialize weights between the input layers and the perceptron\n",
    "W = ???\n",
    "\n",
    "for _ in range(num_epochs):\n",
    "    layer0 = X\n",
    "    # Forward propagation.\n",
    "    # Inside the perceptron, Step 2. \n",
    "    layer1 = ???\n",
    "\n",
    "    # How much did we miss?\n",
    "    layer1_error = ???\n",
    "\n",
    "    # Back propagation.\n",
    "    # multiply how much we missed by the slope of the sigmoid at the values in layer1\n",
    "    layer1_delta = ???\n",
    "\n",
    "    # update weights\n",
    "    W +=  ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expected output.\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 1]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On the training data\n",
    "[int(prediction > 0.5) for prediction in layer1] # All correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can't represent XOR with simple perceptron !!!\n",
    "====\n",
    "\n",
    "No matter how you change the hyperparameters or data, the XOR function can't be represented by a single perceptron layer.\n",
    " \n",
    "There's no way you can get all four data points to get the correct outputs for the XOR boolean operation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solving XOR (Add more layers)\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "def sigmoid(x): # Returns values that sums to one.\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(sx):\n",
    "    # See https://math.stackexchange.com/a/1225116\n",
    "    return sx * (1 - sx)\n",
    "\n",
    "# Cost functions.\n",
    "def cost(predicted, truth):\n",
    "    return truth - predicted\n",
    "\n",
    "xor_input = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "xor_output = np.array([[0,1,1,0]]).T\n",
    "\n",
    "# Define the shape of the weight vector.\n",
    "num_data, input_dim = X.shape\n",
    "# Lets set the dimensions for the intermediate layer.\n",
    "hidden_dim = 5\n",
    "# Initialize weights between the input layers and the hidden layer.\n",
    "W1 = np.random.random((input_dim, hidden_dim))\n",
    "\n",
    "# Define the shape of the output vector. \n",
    "output_dim = len(Y.T)\n",
    "# Initialize weights between the hidden layers and the output layer.\n",
    "W2 = ???\n",
    "\n",
    "# Initialize weigh\n",
    "num_epochs = 10000\n",
    "learning_rate = 0.03\n",
    "\n",
    "for epoch_n in range(num_epochs):\n",
    "    layer0 = X\n",
    "    # Forward propagation.\n",
    "    \n",
    "    # Inside the perceptron, Step 2. \n",
    "    layer1 = sigmoid(np.dot(layer0, W1))\n",
    "    layer2 = ???\n",
    "\n",
    "    # Back propagation (Y -> layer2)\n",
    "    \n",
    "    # How much did we miss in the predictions?\n",
    "    layer2_error = cost(layer2, Y)\n",
    "    # In what direction is the target value?\n",
    "    # Were we really close? If so, don't change too much.\n",
    "    layer2_delta = layer2_error * sigmoid_derivative(layer2)\n",
    "\n",
    "    \n",
    "    # Back propagation (layer2 -> layer1)\n",
    "    # How much did each layer1 value contribute to the layer2 error (according to the weights)?\n",
    "    layer1_error = np.dot(layer2_delta, W2.T)\n",
    "    layer1_delta = ???\n",
    "    \n",
    "    # update weights\n",
    "    W2 +=  learning_rate * np.dot(layer1.T, layer2_delta)\n",
    "    W1 +=  ???\n",
    "    ##print(epoch_n, list((layer2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training input.\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expected output.\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31284349],\n",
       "       [0.6213127 ],\n",
       "       [0.62323891],\n",
       "       [0.46427804]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2 # Our output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 0]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On the training data\n",
    "[int(prediction > 0.5) for prediction in layer2] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try adding another layer\n",
    "====\n",
    "\n",
    "Use the same process:\n",
    "    \n",
    "  1. Initialize\n",
    "  2. Forward Propagate\n",
    "  3. Back Propagate \n",
    "  4. Update (aka step)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "def sigmoid(x): # Returns values that sums to one.\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(sx):\n",
    "    # See https://math.stackexchange.com/a/1225116\n",
    "    return sx * (1 - sx)\n",
    "\n",
    "# Cost functions.\n",
    "def cost(predicted, truth):\n",
    "    return truth - predicted\n",
    "\n",
    "xor_input = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "xor_output = np.array([[0,1,1,0]]).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the shape of the weight vector.\n",
    "num_data, input_dim = X.shape\n",
    "# Lets set the dimensions for the intermediate layer.\n",
    "layer0to1_hidden_dim = 5\n",
    "layer1to2_hidden_dim = 5\n",
    "\n",
    "# Initialize weights between the input layers 0 ->  layer 1\n",
    "W1 = np.random.random((input_dim, ???))\n",
    "\n",
    "# Initialize weights between the layer 1 -> layer 2\n",
    "W2 = np.random.random((???, ???))\n",
    "\n",
    "# Define the shape of the output vector. \n",
    "output_dim = len(Y.T)\n",
    "# Initialize weights between the layer 2 -> layer 3\n",
    "W3 = np.random.random((???, output_dim))\n",
    "\n",
    "# Initialize weigh\n",
    "num_epochs = 10000\n",
    "learning_rate = 1.0\n",
    "\n",
    "for epoch_n in range(num_epochs):\n",
    "    layer0 = X\n",
    "    # Forward propagation.\n",
    "    \n",
    "    # Inside the perceptron, Step 2. \n",
    "    layer1 = sigmoid(np.dot(layer0, W1))\n",
    "    layer2 = ???\n",
    "    layer3 = ???\n",
    "\n",
    "    # Back propagation (Y -> layer2)\n",
    "    # How much did we miss in the predictions?\n",
    "    layer3_error = ???\n",
    "    # In what direction is the target value?\n",
    "    # Were we really close? If so, don't change too much.\n",
    "    layer3_delta = ???\n",
    "\n",
    "    # Back propagation (layer2 -> layer1)\n",
    "    # How much did each layer1 value contribute to the layer3 error (according to the weights)?\n",
    "    layer2_error = ???\n",
    "    layer2_delta = ???\n",
    "    \n",
    "    # Back propagation (layer2 -> layer1)\n",
    "    # How much did each layer1 value contribute to the layer2 error (according to the weights)?\n",
    "    layer1_error = ???\n",
    "    layer1_delta = layer1_error * sigmoid_derivative(layer1)\n",
    "    \n",
    "    # update weights\n",
    "    W3 +=  learning_rate * np.dot(layer2.T, layer3_delta)\n",
    "    W2 +=  ???\n",
    "    W1 +=  ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50039537],\n",
       "       [0.50000003],\n",
       "       [0.9929507 ],\n",
       "       [0.50001378]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On the training data\n",
    "[int(prediction > 0.5) for prediction in layer3] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, lets do it with PyTorch \n",
    "\n",
    "First lets try a single perceptron and see that we can't train a model that can represent XOR. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch import FloatTensor\n",
    "from torch import optim\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set(rc={'figure.figsize':(15, 10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X # Original XOR X input in numpy array data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y # Original XOR Y output in numpy array data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]])\n",
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "device = 'gpu' if torch.cuda.is_available()  else 'cpu'\n",
    "# Converting the X to PyTorch-able data structure.\n",
    "X_pt = torch.tensor(X).float()\n",
    "X_pt = X_pt.to(device)\n",
    "# Converting the Y to PyTorch-able data structure.\n",
    "Y_pt = torch.tensor(Y, requires_grad=False).float()\n",
    "Y_pt = Y_pt.to(device)\n",
    "print(X_pt)\n",
    "print(Y_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs Dim: 2\n",
      "Output Dim: 1\n"
     ]
    }
   ],
   "source": [
    "# Use tensor.shape to get the shape of the matrix/tensor.\n",
    "num_data, input_dim = X_pt.shape\n",
    "print('Inputs Dim:', input_dim)\n",
    "\n",
    "num_data, output_dim = Y_pt.shape\n",
    "print('Output Dim:', output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=1, bias=True)\n",
       "  (1): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use Sequential to define a simple feed-forward network.\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim), # Use nn.Linear to get our simple perceptron\n",
    "            nn.Sigmoid()                      # Use nn.Sigmoid to get our sigmoid non-linearity\n",
    "        )\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember we define as: cost = truth - predicted\n",
    "# If we take the absolute of cost, i.e.: cost = |truth - predicted|\n",
    "# we get the L1 loss function. \n",
    "criterion = nn.L1Loss() \n",
    "learning_rate = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The simple weights/parameters update processes we did before\n",
    "# is call the gradient descent. SGD is the sochastic variant of\n",
    "# gradient descent. \n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(**Note**: Personally, I strongely encourage you to go through the [University of Washington course of machine learning regression](https://www.coursera.org/learn/ml-regression) to better understand the fundamentals of (i) ***gradient***, (ii) ***loss*** and (iii) ***optimizer***. But given that you know how to code it, the process of more complex variants of gradient/loss computation and optimizer's step is easy to grasp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a PyTorch model\n",
    "\n",
    "To train a model using PyTorch, we simply iterate through the no. of epochs and imperatively state the computations we want to perform. \n",
    "\n",
    "## Remember the steps?\n",
    "\n",
    " 1. Initialize \n",
    " 2. Forward Propagation\n",
    " 3. Backward Propagation\n",
    " 4. Update Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:01<00:00, 5796.33it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Initialization. \n",
    "# Note: When using PyTorch a lot of the manual weights\n",
    "#       initialization is done automatically when we define\n",
    "#       the model (aka architecture)\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim), \n",
    "            nn.Sigmoid())\n",
    "criterion = nn.MSELoss() \n",
    "learning_rate = 1.0\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "num_epochs = 10000\n",
    "\n",
    "losses = []\n",
    "\n",
    "for i in tqdm(range(num_epochs)):\n",
    "    # Reset the gradient after every epoch. \n",
    "    optimizer.zero_grad() \n",
    "    # Step 2: Foward Propagation\n",
    "    predictions = model(X_pt)\n",
    "    \n",
    "    # Step 3: Back Propagation \n",
    "    # Calculate the cost between the predictions and the truth.\n",
    "    loss_this_epoch = criterion(predictions, Y_pt)\n",
    "    # Note: The neat thing about PyTorch is it does the \n",
    "    #       auto-gradient computation, no more manually defining\n",
    "    #       derivative of functions and manually propagating\n",
    "    #       the errors layer by layer.\n",
    "    loss_this_epoch.backward()\n",
    "    \n",
    "    # Step 4: Optimizer take a step. \n",
    "    # Note: Previously, we have to manually update the \n",
    "    #       weights of each layer individually according to the\n",
    "    #       learning rate and the layer delta. \n",
    "    #       PyTorch does that automatically =)\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Log the loss value as we proceed through the epochs.\n",
    "    losses.append(loss_this_epoch.data.item())\n",
    "    \n",
    "# Visualize the losses\n",
    "plt.plot(losses)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\t [0, 0]\n",
      "Pred:\t 0\n",
      "Ouput:\t 0\n",
      "######\n",
      "Input:\t [0, 1]\n",
      "Pred:\t 0\n",
      "Ouput:\t 1\n",
      "######\n",
      "Input:\t [1, 0]\n",
      "Pred:\t 0\n",
      "Ouput:\t 1\n",
      "######\n",
      "Input:\t [1, 1]\n",
      "Pred:\t 0\n",
      "Ouput:\t 0\n",
      "######\n"
     ]
    }
   ],
   "source": [
    "for _x, _y in zip(X_pt, Y_pt):\n",
    "    prediction = model(_x)\n",
    "    print('Input:\\t', list(map(int, _x)))\n",
    "    print('Pred:\\t', int(prediction))\n",
    "    print('Ouput:\\t', int(_y))\n",
    "    print('######')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, try again with 2 layers using PyTorch\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:01<00:00, 3764.65it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.55 s, sys: 84.7 ms, total: 1.63 s\n",
      "Wall time: 1.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hidden_dim = 5\n",
    "num_data, input_dim = X_pt.shape\n",
    "num_data, output_dim = Y_pt.shape\n",
    "\n",
    "model = nn.Sequential(nn.Linear(???, ???),\n",
    "                      ???, \n",
    "                      nn.Linear(???, ???),\n",
    "                      nn.Sigmoid())\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 0.3\n",
    "optimizer = ???\n",
    "num_epochs = 5000\n",
    "\n",
    "losses = []\n",
    "\n",
    "for _ in tqdm(range(num_epochs)):\n",
    "    optimizer.zero_grad()\n",
    "    predictions = ???\n",
    "    loss_this_epoch = ???\n",
    "    loss_this_epoch.???\n",
    "    optimizer.???\n",
    "    losses.append(loss_this_epoch.data.item())\n",
    "    ##print([float(_pred) for _pred in predictions], list(map(int, Y_pt)), loss_this_epoch.data[0])\n",
    "    \n",
    "# Visualize the losses\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\t [0, 0]\n",
      "Pred:\t 0\n",
      "Ouput:\t 0\n",
      "######\n",
      "Input:\t [0, 1]\n",
      "Pred:\t 1\n",
      "Ouput:\t 1\n",
      "######\n",
      "Input:\t [1, 0]\n",
      "Pred:\t 1\n",
      "Ouput:\t 1\n",
      "######\n",
      "Input:\t [1, 1]\n",
      "Pred:\t 1\n",
      "Ouput:\t 0\n",
      "######\n"
     ]
    }
   ],
   "source": [
    "for _x, _y in zip(X_pt, Y_pt):\n",
    "    prediction = model(_x)\n",
    "    print('Input:\\t', list(map(int, _x)))\n",
    "    print('Pred:\\t', int(prediction > 0.5))\n",
    "    print('Ouput:\\t', int(_y))\n",
    "    print('######')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST: The \"Hello World\" of Neural Nets\n",
    "====\n",
    "\n",
    "Like any deep learning class, we ***must*** do the MNIST. \n",
    "\n",
    "The MNIST dataset is \n",
    "\n",
    " - is made up of handwritten digits \n",
    " - 60,000 examples training set\n",
    " - 10,000 examples test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (0.2.2.post3)\r\n",
      "Requirement already satisfied: torch in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from torchvision) (1.2.0)\r\n",
      "Requirement already satisfied: pillow>=4.1.1 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from torchvision) (5.2.0)\r\n",
      "Requirement already satisfied: numpy in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from torchvision) (1.17.2)\r\n",
      "Requirement already satisfied: six in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from torchvision) (1.12.0)\r\n"
     ]
    }
   ],
   "source": [
    "# We're going to install tensorflow here because their dataset access is simpler =)\n",
    "!pip3 install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = datasets.MNIST('../data', train=True, download=True, \n",
    "                             transform=transforms.Compose([\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "mnist_test = datasets.MNIST('../data', train=False, download=True, \n",
    "                             transform=transforms.Compose([\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.1307,), (0.3081,))\n",
    "                             ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization Candies\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_image(mnist_x_vector, mnist_y_vector):\n",
    "    pixels = mnist_x_vector.reshape((28, 28))\n",
    "    label = np.where(mnist_y_vector == 1)[0]\n",
    "    plt.title('Label is {}'.format(label))\n",
    "    plt.imshow(pixels, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fifth image and label.\n",
    "show_image(mnist_train.data[5], mnist_train.targets[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets apply what we learn about multi-layered perceptron with PyTorch and apply it to the MNIST data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mnist = mnist_train.data.float()\n",
    "Y_mnist = mnist_train.targets.float()\n",
    "\n",
    "X_mnist_test = mnist_test.data.float()\n",
    "Y_mnist_test = mnist_test.targets.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_mnist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of images: 60000\n",
      "Inputs Dim: [28, 28]\n",
      "Output Dim: []\n"
     ]
    }
   ],
   "source": [
    "# Use FloatTensor.shape to get the shape of the matrix/tensor.\n",
    "num_data, *input_dim = X_mnist.shape\n",
    "print('No. of images:', num_data)\n",
    "print('Inputs Dim:', input_dim)\n",
    "\n",
    "num_data, *output_dim = Y_mnist.shape\n",
    "num_test_data, *output_dim = ???\n",
    "print('Output Dim:', output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the dimensions of the images.\n",
    "X_mnist = mnist_train.data.float().view(num_data, -1)\n",
    "Y_mnist = mnist_train.targets.float().unsqueeze(1)\n",
    "\n",
    "X_mnist_test = mnist_test.data.float().view(num_test_data, -1)\n",
    "Y_mnist_test = mnist_test.targets.float().unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of images: 60000\n",
      "Inputs Dim: [784]\n",
      "Output Dim: []\n"
     ]
    }
   ],
   "source": [
    "# Use FloatTensor.shape to get the shape of the matrix/tensor.\n",
    "num_data, *input_dim = X_mnist.shape\n",
    "print('No. of images:', num_data)\n",
    "print('Inputs Dim:', input_dim)\n",
    "\n",
    "num_data, *output_dim = Y_mnist.shape\n",
    "num_test_data, *output_dim = Y_mnist_test.shape\n",
    "print('Output Dim:', output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD7CAYAAABpJS8eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXiU1d3/8fdMFhIghBACBJKQsJ2ENRgSVNwXyqJWq6CCxgBqW2t9rFJqS9jEp7VPrfZXq7YlCCgouIELsrhRcSFhX8MJu6gBQkB2CCH8/sjwPDQFMgmTWTKf13VxXZl75mQ+x9vrmzPnnvmO4/Tp04iISP3n9HUAERHxDhV8EZEgoYIvIhIkVPBFRIKECr6ISJAI9XWA82gAZALFwCkfZxERCRQhQDywFDhR9U5/LfiZwGJfhxARCVBXAl9UPeivBb8YYP/+I1RU1PxzArGxjSktPezxUP5Mcw4OmnNwqO2cnU4HMTGNwFVDq/LXgn8KoKLidK0K/pmxwUZzDg6ac3C4yDmfcytcF21FRIKECr6ISJBQwRcRCRIq+CIiQUIFX0QkSKjgi4gEiXpX8L/be4ScJxcwP/8bTlVU+DqOiIjfqHcFPy46gvZtmvLGZ5v5/avL+XZPcH1gQ0TkfOpdwQ8PCyF3eBY/+3EX9h44zoSpS5mzeCsny7XaF5Hg5q+ftL0oDoeDrLSWpLWNYeYnm3jvy+0styXkDEilfetoX8cTEfGJerfCP1tUw3AeuLkL/3VHd46eKOf3ryxn5iebOFGmBpwiEnzq5Qq/qh4dmvNUYlPeWrSFhUt3sqKohJz+qXRObubraCIiXlOvV/hni2wQyr0/MvxmSE+cTgfPzFzF1HmFHD1+0tfRRES8ImgK/hkmKYYnh2fRv3cSi9cUMzovn5VFJb6OJSJS54Ku4EPlO3kGXduB3OxeREWG8/w7a/n7u+s4eKTM19FEROpMUBb8M1LimzA2pxe3XZnCiqISRk9awtfrdnH6dPD13haR+i+oCz5AaIiTm/ukMG5YFq2aNWTSBxv4y5trKD1w3NfRREQ8yq136RhjxgGDXTfnWmtHGWN+DjwMOIC5wChr7ekq47KBPwK7zxo72iPJPaxN80b89p4MPln+LW9/voXcyfkMvqY9V/dsg9Ph8HU8EZGLVm3BN8bcAPQFegKngfnGmF8BDwHpwHHgc+BGYGGV4ZnAY9ba1z0Zuq44nQ5uzEwkvWNzps3fyKsLi8jfsJucAWm0atbQ1/FERC6KO1s6xcDj1toya+1JoBCoADpba48ATYFo4IdzjM0Eso0xq40x040xMZ4KXpfimkby+J3pDOufys6SI4x7uYB5S3aoGZuIBDRHTS5QGmM6Al8Bl1trNxljHgCeAQqAgdbasiqPnw087br/90CStXaoG0+VDGxzO1gdKj1wjL+/s4Yl63bRPiGa/7qzJylqzyAi/i0F2F71oNsF3xjThcq9+nHW2mlnHQ8FpgA7rbW/u8D4GGCrtdadVX4ysK209HCtvrk9Li6KkpJDNR53PqdPn2a5LWH6QsuR4+X0v7QtN1+eTFio/1zz9vScA4HmHBw0Z/c5nQ5iYxvDeQq+WxXLGNMH+AR4wlo7zRiT6DqGtbYcmAl0rzIm2rXXf4YDCMiPtTocDnqltuCpBy6ld+eWfPDVdsZPKWDztwd8HU1ExG3VFnxjTCIwBxhirZ3pOhwNzDDGNDXGOIA7gC+qDD0MjDLG9HbdfhiY7ZnYvtE4Moz7b+rMrwb3oOzkKf4wfTmvfVTE8bJyX0cTEamWO2/LHAlEAM8aY84c+zvwByr388uBxcCfAYwxecB71tr3jDGDgZeMMZFAEZDt2fi+0a1dLE+O6M3b/9rCx8u/ZdXmvdzXL5UuKWrGJiL+q0YXbb0oGT/aw7+Qop0/MGXeRnbvO8oV3eK58/oONIoI88pzn037nMFBcw4OPt3Dl/PrlNiUJ4dnMvCytny1bhe5k/JZbtWMTUT8jwq+B4SFhnD71e0Zc18vohuF88Lstbw4ey0HDp/wdTQRkf+lgu9BbVtFkXtfL26/uh2rNpeSm5fPl2uL1YxNRPyCCr6HhYY4GXhZMhOGZxIf24jJcwt57o3V7D1wzNfRRCTIqeDXkfjYRjxxzyUMvbETm749wJi8Aj5Z/i0VWu2LiI+o4Nchp8PB9RkJTByRRYeEaGZ8VMTTM1ZQXHrE19FEJAip4HtB86aRPDa4ByMGplG89wjjXl7K3K+3U35KzdhExHvc6ocvF8/hcNCnWzxdU5ox46Mi3v7XVpZu3MOw/mm0bRXl63giEgS0wvey6MYNeOi2bvzitq78cLiMidOW8fa/tnCy/JSvo4lIPacVvo9kmBakto1h1iebmfv1DpbZEob1T6VTYlNfRxORekorfB9qFBHG8IFpPHZnD8rLK3h6xgqmL7QcO6FmbCLieSr4fqBrSiwT78/ihowEPlvxHWMn57Nua6mvY4lIPaOC7yciwkMZcmMnfntPBuFhITz7xmryPtjA4WMB+RUCIuKHVPD9TIeEaMYPy+Smy9uSv2E3uZOWsGzjHl/HEpF6QAXfD4WFhvCTqyqbscVERfDinHX87Z21/KBmbCJyEVTw/VhSyyhy78vgjmvas2ZLKbmT8lm85ns1YxORWlHB93MhTicDLm3LkyOySIhrxJQPN/LnWaso+UHN2ESkZlTwA0SrZg0ZNfQS7u3biS3fH2TM5Hw+WrazVt8IJiLBSQU/gDgdDq69JIGnRvTGJMbw+seb+MOM5Xy/V83YRKR6bn3S1hgzDhjsujnXWjvKGPNz4GHAAcwFRllrT1cZlwRMB1oAFhhqrT3sqfDBKjY6gkcHdWfJ+t289nER46cUcFdfw1VdWxEaor/hInJu1VYHY8wNQF+gJ5AOZBhjfgU8BmQB3YDLgRvPMfxF4EVrbSqwDBjjodxBz+FwcFnXVvz3A5fSs2Mc0+dt5Mmpy9i+66Cvo4mIn3JnOVgMPG6tLbPWngQKgQqgs7X2CNAUiAZ+OHuQMSYMuAp4y3VoKjDIQ7nFpUmjcH5+a1d+l5PFoWOVzdje/GwzZSfVjE1E/l21WzrW2vVnfjbGdATuBC631p40xjwAPAMUAKuqDG0OHLTWnmkMUwwkeCS1/IfLusXTumkDZn26mXn537CiqISc/qmYpBhfRxMRP+Fw9z3dxpguVO7Vj7PWTjvreCgwBdhprf3dWcdbAwXW2oSzHnfYWhvhxtMlA9vcnYT8u9VFJTz/5ip27ztK/8uTyRnYmYYRYb6OJSLekwJsr3rQ3Yu2fYC3gUettTONMYlAkrX2S2ttuTFmJvDzKsNKgCbGmBBr7SkgHvi+JolLSw/X6m2HcXFRlJQcqvG4QHb2nFvHRDA+J5PZi7cy/6vt5K8rJvtHhu7tm/s4pWcF+3kOFpqz+5xOB7Gxjc9/f3W/wFXc5wBDrLUzXYejgRnGmKbGGAdwB/DF2eNc+/2LqdwCAsgG5tV4BlIrDcJDuOv6jvzu3gwiwkP5y5trmPT+eg4dLfN1NBHxEXdW+COBCOBZY8yZY38H/gB8BZRTWdj/DGCMyQPes9a+BzwETDPG5ALfAHd7NL1Uq32baMblZDL36+3M/XoH67btY+iNnchMbYHD4fB1PBHxIrf38L0sGdimLR33uTPnnXsOM+XDQrbvOkR6h+bc+yNDTFQDLyX0PJ3n4KA5u++sLZ1z7uHrUzpBJLFFY0ZnZzD42g6s376P3Lx8Pl+tZmwiwUIFP8iEOJ30653EkyOySGrRmKnzNvLMzFXsUTM2kXpPBT9ItYxpyK+H9CS7n2Fb8UHG5uWzsOAbNWMTqcfcelum1E9Oh4Nr0tvQvV0sryywzPx0MwUb9zCsfypt4s7/1i4RCUxa4QvNmkTwX3d058FbOrNn/zHGT1nKe19so/xUha+jiYgHaYUvQGUztks7t6JzcjNe/3gTc77YxlK7h+ED0kiJb+LreCLiAVrhy79p0jCcn97ShUdu787R4+U89coyZn26iRNqxiYS8LTCl3NK79icTolNeWvRZhYU7GRl0V5y+qeS2lbN2EQClVb4cl4NI0LJ7pfKr+/uCcD/vL6SafM3cvR4eTUjRcQfqeBLtdLaxjBhRBb9spL4fPX3jJmcz6rNe30dS0RqSAVf3NIgLITB13Vg9L29aBgRyl/fWsM/3lvPQTVjEwkYKvhSI+1aN2FcTia3XpHCso17yJ2Uz5L1u9SeQSQAqOBLjYWGOLnlihTGDcskrmkk/3x/A399aw37Dh73dTQRuQAVfKm1hLjGjL43g7uu60Dhjv3k5uWzaOV3VGi1L+KXVPDlojidDvpmJfHk/b1JiW/CKwssz7y+kt37j/o6mohUoYIvHtGiaSQj70onp38qO3YfYuzkAubnf8OpCrVnEPEX+uCVeIzD4eCqHq3p1i6WVxdY3vhsM0s37mZY/zQSWqgZm4ivaYUvHhcT1YBf3t6Nn/24C3sPHGfC1KXMWbyVk+Va7Yv4klb4UiccDgdZaS1JaxvDzE828d6X21lmSxjWP5X2baJ9HU8kKGmFL3UqqmE4D9zchUcHdefYiXJ+/+pyZn6yiRNlasYm4m1urfCNMeOAwa6bc621o4wxDwKPAKeBZcBPrbVlVcZlA38Edp81drRHkktA6d6+OU/d35S3Fm1h4dKdrCgqIad/Kp2Tm/k6mkjQqLbgG2NuAPoCPaks7vONMb8B7gcygEPAVOAXwHNVhmcCj1lrX/dgZglQkQ1CufdHhqy0Fv/7XbpX9Yhn8LUdaBgR5ut4IvWeO1s6xcDj1toya+1JoBCIAH5urT1orT0NrAWSzjE2E8g2xqw2xkw3xqi3rmCSYpgwPIv+vZNYvKaY0Xn5rCwq8XUskXqv2oJvrV1vrV0CYIzpCNwJvGat/dh1LA54GHj3HMOLgfFAOrAT+JtnYkugCw8LYdC1HcjN7kVUZDjPv7OWl+as48ARNWMTqSsOd5teGWO6AHOBcdbaaa5jbYB5wJvW2onVjI8Btlpr3VnlJwPb3AomAa/8VAVvf7aJmQuLiGwQwgO3duOaSxJwOBy+jiYSqFKA7VUPunvRtg/wNvCotXam61gqMB943lr753OMiQaGW2vP7Os7gJM1SVxaepiKipr3ZYmLi6Kk5FCNxwWyQJ/zdT1ak9omminzCnn2tRV8tGQH2T8yxEZHnHdMoM+5NjTn4FDbOTudDmJjz/8hx2q3dIwxicAcYMhZxT4KWAjknqvYuxwGRhljertuPwzMrkF2CTKtmzfit0MzuPuGjtid+8mdnM9nK75VMzYRD3FnhT+Syou0zxpjzhybBbQERhpjRrqOvWetHWuMyXP9/J4xZjDwkjEmEigCsj0bX+obp9PBjb0SSe/QnGnzN/LqwiLyN+wmZ0AarZo19HU8kYDm9h6+lyUD27Sl4776OOfTp0/zxdpiZn2ymZOnKrj1ihT6ZiUS4qx8YVof51wdzTk4eGBLp/Z7+CK+4HA4uLJ7ZTO26QuLeHPRFgoK9zBsQCpJLaN8HU8k4Ki1gvi9po0b8IvbuvLQrV3Zf+g4E6ct453Pt1B2Uu0ZRGpCK3wJCA6Hg16pLUhtG8OsTzbxwVc7WLW5lOy+hg4JasYm4g6t8CWgNI4MY8RNnXlscA9OnDzFH6Yv57WPijheVu7raCJ+TwVfAlLXdrH8beS1XHdJAh8v/5axkwtYv22fr2OJ+DUVfAlYDSPCGNq3E08MvYTQECd/nrWKl+cWcuR4jT7fJxI0VPAl4HVKbMqE4ZkMvKwtX63bRe6kfJbbPb6OJeJ3VPClXggLDeH2q9sz5r5eRDcK54XZ63hh9loOHD7h62gifkMFX+qVtq2iyL2vF7df3Y7Vm0vJzcvny7XF+OkHDEW8SgVf6p3QECcDL0tmwvBM4ps3YvLcQp57YzV7DxzzdTQRn1LBl3orPrYRTwy9hKE3dmLTtwcYk1fAJ8vVjE2Clwq+1GtOh4PrMxKYeH8WHROimfFREU/PWEFx6RFfRxPxOhV8CQrNoyP51eAejBiYRvHeI4x7uYAPvtpO+akKX0cT8Rq1VpCg4XA46NMtnq4pzZjxURHvfL6VZRv3MGxAGm1bqRmb1H9a4UvQiW7cgIdu68YvbuvKgSNlTJy2jLcWbeFkuZqxSf2mFb4ErQxzphnbZj5csoPlRSUM659Kp8Smvo4mUie0wpeg1igijOED03j8znROnarg6RkrmL7QcuyEmrFJ/aOCLwJ0SWnGkyOyuCEjgc9WfMfYyfms3Vrq61giHqWCL+ISER7KkBs78dt7MggPC+G5N1aT98EGDh9TMzapH9zawzfGjAMGu27OtdaOMsY8CDwCnAaWAT+11pZVGZcETAdaABYYaq097KnwInWhQ0I044dl8v5XO5i3ZAfrtpZyT19DhonD4XD4Op5IrVW7wjfG3AD0BXoC6UCGMeY3wK+By4Hurt/zi3MMfxF40VqbSuUfhTEeyi1Sp8JCQ/jJVe0Yc18vYppE8OKcdbwwex0/qBmbBDB3tnSKgcettWXW2pNAIRAB/Nxae9BaexpYCySdPcgYEwZcBbzlOjQVGOSp4CLekNQyitzsDAZd0561W0vJnZTP4jXfqxmbBKRqt3SstevP/GyM6QjcCVxurd3kOhYHPAzkVBnaHDhorT3zdodiIMEDmUW8KsTppP+lbenZKY6pHxYy5cON5G/YzX39UolrGunreCJuc7i7UjHGdAHmAuOstdNcx9oA84A3rbUTqzy+NVBgrU1w3Q4FDltrI9x4umRgm7uTEPGWiorTzF+ynakfrKfiNGT3T2PgFe0IcWpvX/xKCrC96kG3Cr4xpg/wNvCotXam61gqMB943lr753OMCQNKgRhr7SljTCLwL2ttOzfCJgPbSksPU1FR85fOcXFRlJQcqvG4QKY5e1fpgeO8ssCydmsp7ds0Iad/Gm2aN6rz59V5Dg61nbPT6SA2tjGcp+C7c9E2EZgDDDmr2EcBC4HccxV7ANd+/2Iqt4AAsql8NSAS8GKjI3h0UHceuKkzu/cdY8KUAt7/cpuasYlfc+dtmSOpvEj7rDHmzLFZQEtgpDFmpOvYe9bascaYPNfP7wEPAdOMMbnAN8DdHk0v4kMOh4PLuraiS0ozXvu4iNmLt7F0YwnDB6aS3KqJr+OJ/Ae39/C9LBlt6dSI5ux7K4tKeGWh5eCRMvplJfHjK1IIDwvx6HP425y9QXN2X3VbOmqeJuIhPTvFYZKa8sZnm5mX/w0rikrI6Z+KSYrxdTQRQK0VRDyqYUQYOf3TGHlXOqcqTvPH11by6gI1YxP/oIIvUgc6Jzdj4oje9M1MZNHK78jNy2fNlr2+jiVBTgVfpI40CA/hrus78rt7M4hsEMpf3lzDP99fz6GjZdUPFqkDKvgidax9m2jG5WRyS59klhbuITcvn4LC3WrPIF6ngi/iBWGhTm69sh3jcjKJbRLB399dz/Nvr2X/ITVjE+9RwRfxooQWjRmdncHgazuwfvs+cvPy+Xy1mrGJd6jgi3hZiNNJv95JPDkii6QWjZk6byPPzFzFnv1HfR1N6jkVfBEfaRnTkF8P6Ul2P8P2XQcZO7mABQXf1OrDhiLu0AevRHzI6XBwTXobureL5dUFllmfbqagcA/DBqSSENfY1/GkntEKX8QPNGsSwSN3dOfBWzpT8sMxJkxZyrtfqBmbeJZW+CJ+wuFwcGnnVnRObsbMjzfx7hfbWGb3MHxAGinxasYmF08rfBE/06RhOA/e0oVHbu/O0ePlPPXKMmZ9uokTJ0/5OpoEOK3wRfxUesfmdEpsyluLNrOgYCcri/byX3f3JD7anS+NE/lPWuGL+LGGEaFk90tl1N09ARj90ldMm7+Ro8fVjE1qTgVfJACkto1hwogsbrumA5+v/p7cvCWs2qRmbFIzKvgiAaJBWAjDb+5CbnYvGkeG8de31/CP99ZzUM3YxE0q+CIBJiW+CWNzMrn1ihSWbdxD7qR8lqzfpfYMUi0VfJEAFBri5JYrUhg/LJMWMZH88/0N/PWtNew7eNzX0cSPqeCLBLA2cY353T0Z3HVdBwp37Cc3L59FK7+jQqt9OQe33pZpjBkHDHbdnGutHeU6HgbMByZaaxedY1w28Edg91ljR19saBH5P06ng75ZSaR3imPavI28ssCSv2E3Of1Tadmsoa/jiR+ptuAbY24A+gI9gdPAfGPMbcAG4GXgkgsMzwQes9a+7oGsInIBLZpGMvKudBavKWbWp5sZ+3IBt13ZjhszEwhx6sW8uLfCLwYet9aWARhjCoEk4DLgT8CjFxibCXQwxjwBrAV+aa3df3GRReR8HA4HV/VoTbd2sUxfaHnjs80UFO5m2IA0EluoGVuwq/bPvrV2vbV2CYAxpiNwJ/ChtXaUtXZONcOLgfFAOrAT+NvFxRURd8RENeDhn3TjZz/uQunB4zw5dSlzFm/lZLmasQUzh7tv5TLGdAHmAuOstdPOOr4IGH+uPfwq42OArdbaGDeeLhnY5lYwEbmgg0fKmPTuWhYt/5bEllE8cmc6qW2b+TqW1K0UYHvVg+5etO0DvA08aq2d6eaYaGC4tfY51yEHcNKtqC6lpYdr9WUQcXFRlJQcqvG4QKY5B4fazjn7xk6kt2vGtPmWUX9dzI2Zidx2ZTsahIfUQUrP0nl2n9PpIDb2/Ft31W7pGGMSgTnAEHeLvcthYJQxprfr9sPA7BqMFxEP6t6+OU/d35trLmnDwqU7GTM5nw3b9/k6lniRO5fuRwIRwLPGmFWufz8734ONMXnGmFustaeofCvnS64LvRnAKI+kFpFaiWwQyr19Db8Z0pMQp4NnZq5iyoeFHD1eoxffEqDc3sP3smRgm7Z03Kc5BwdPzrns5Cne/XIbC/J3EtUojOy+hp6d4jzyuz1J59l9Z23pnHMPX2/OFQlS4WEhDLqmA7n3ZdCkYTjPv7OWl+as48ARNWOrr1TwRYJccqsmjLmvF7dd1Y6Vm0rInbSEr9epGVt9pIIvIoSGOLn58mTGD8uiVWxDJn2wgb+8uYbSA2rGVp+o4IvI/2rdvBG/HZrB3Td0xO7cT+7kfD5d8a2asdUTKvgi8m+cTgc39krkqRG96dC6CdMXFvE/M1awa99RX0eTi6SCLyLn1LxpJI/dmc7wAWl8W3KEsZML+HDJDk5VqD1DoHLrk7YiEpwcDgdXdI+na7tmTF9YxFuLtrC0cA/DBqSS1DLK1/GkhrTCF5FqNW1c2YztoVu7sv/wCSZOW8Y7n2/hZPkpX0eTGtAKX0Tc1iu1BaltY5j1ySY++GoHy20Jw/qn0SEh2tfRxA1a4YtIjTSODGPETZ15bHAPyk6e4g/TlzPjoyKOl5X7OppUQwVfRGqla7tYnhzRm+suSeDT5d8yJq+AddtKfR1LLkAFX0RqLbJBKEP7duI3Qy8hLNTJs7NWM3nuBo6oGZtfUsEXkYvWKbEpE4ZnMvCytny9bje5k/JZbvf4OpZUoYIvIh4RFhrC7Ve3Z8x9vYhuFM4Ls9fxwuy1HDh8wtfRxEUFX0Q8qm2rKHLv68XtV7dj9eZScvPy+XJtsZqx+QEVfBHxuNAQJwMvS2bC8Ezimzdi8txCnn1jNXt/OObraEFNBV9E6kx8bCOeGHoJQ2/sxObvDjBmcgEfL9upZmw+ooIvInXK6XBwfUYCE0dk0TEhmtc+3sTTM1ZQXHrE19GCjgq+iHhF8+hIfjW4ByMGplG89wjjXi7gg6+2U35Kzdi8Ra0VRMRrHA4HfbrF07VdLDMWWt75fCvLNu5h2IA02rZSM7a65lbBN8aMAwa7bs611o5yHQ8D5gMTrbWLzjEuCZgOtAAsMNRae9gDuUUkgEU3Cueh27qx3JYwfaFl4rRl9OudxC19kgkPC/F1vHqr2i0dY8wNQF+gJ5AOZBhjbjPGGGARcPkFhr8IvGitTQWWAWMuOrGI1BsZJo6nHujN5d1a8eGSHYybspSinT/4Ola95c4efjHwuLW2zFp7EigEkoARwJ+A/HMNcq3+rwLech2aCgy62MAiUr80ighj+IA0Hr8rnVOnKnh6xgqmL7QcO6FmbJ5W7ZaOtXb9mZ+NMR2BO4HLrbWbXMcePc/Q5sBBa+2Zs1YMJNQkXGxs45o8/N/ExQXffqDmHBzq65yviYuid/c2TJ9XyPtfbGXttn384o4exMVF1ds5X0hdzNnti7bGmC7AXGDkmWJfDcc5jtXocnxp6WEqKmr+ft24uChKSg7VeFwg05yDQzDM+dY+yXRNjmHKh4WMn7SE63olcmufZBpHhvk6mtfU9jw7nY4LLpTdelumMaYP8AnwhLV2mpvPXQI0McacuQITD3zv5lgRCWId2kQzflgWN12ezL9WfEvupCUs27hH7RkukjsXbROBOcAQa+1Md3+xa79/MZVbQADZwLzahBSR4BMW6uQnV7XjuV9dTUyTCF6cs44XZq/jBzVjqzV3VvgjgQjgWWPMKte/n53vwcaYPGPMLa6bDwEPGmM2AFcCuRedWESCSkrraHKzMxh0bXvWbi1l9KR8Fq/+Xqv9WnD46X+0ZGCb9vDdpzkHh2Cf8659R5k6byNFO3+gc3IM9/VLJa5ppI8Tep4H9vBTgO3/cf9FJxMR8ZJWzRoyakhP7v2RYev3BxkzOZ+Plu6s1cIwGKngi0hAcTocXNuzDU/d3xuTGMPrn2ziDzOW891eNWOrjgq+iASkZk0ieHRQdx64uTO79x1jwpQC3v9ym5qxXYCap4lIwHI4HFzWpRVdkpvx2sdFzF68jaUbSxg2IJWU+Ca+jud3tMIXkYDXpFE4P/txV355ezcOHyvjqVeW8cZnmyk7ecrX0fyKVvgiUm/07BiHSWzKG59tYX7+N6woKmFY/1RMUoyvo/kFrfBFpF5pGBFGTv9Ufn1XOqdPn+aPr63klQVqxgYq+CJST6UlN+PJ4b3pm5nIv1Z9R25ePmu27PV1LJ9SwReReqtBeAh3Xd+R392bQWSDUP7y5hr++f56Dh0t83U0n1DBF5F6r33raMblZHJLn2SWFu4hNy+fgsLdQdeeQQVfRIJCWKiTW69sx7icTJpHR/D3d9fz/Ntr2X8oeGu0K8oAAAjXSURBVJqxqeCLSFBJaNGY0ff2YvC1HdiwfR+5eUv416rvgmK1r4IvIkHH6XTQr3cSE0Zk0bZlFNPmW/70+kr27D/q62h1SgVfRIJWy5iGjLy7J9n9DDt2H2Ls5AIWFHxTb5ux6YNXIhLUnA4H16S3oXu7WF5dYJn16WYKCvcwbEAqCXG1/15tf6QVvogIlc3YHrmjOz+9pQslPxxjwpSlvPtF/WrGphW+iIiLw+Ggd+eWdE6O4fWPN/HuF9tYZvcwrH8a7VoHfjM2rfBFRKqIahjOg7d04ZE7unP0eDn//eoyZn26iRMB3oxNK3wRkfNI79CcTglNeWvRZhYU7GRFUQk5/dNIaxuYzdjcKvjGmHHAYNfNudbaUcaYG4BngUhglrX2P76g3BiTDfwR2H3W2NEXH1tExDsaRoSS3S+VrLSWTJ23kT+9vpKr01sz6JoONIwIrDVztWldhb0v0BM4Dcw3xtxNZSG/GtgJzDXG9LfWzqsyPBN4zFr7umdji4h4V2rbGCaMyOLdxdtYsPQbVm/eS/aPUknv2NzX0dzmzh5+MfC4tbbMWnsSKAQ6AZustdusteXAdGDQOcZmAtnGmNXGmOnGmMB8HSQiAjQIC2HwdR3Ize5F48gw/vr2Gv7x3noOBkgztmoLvrV2vbV2CYAxpiNwJ1BB5R+CM4qBhHMMLwbGA+lUvhL420XmFRHxuZT4JozNyeTWK1NYtnEPuZPyWbJ+l9+3Z3C4G9AY0wWYC4wDTgIDrLX3uO67ARhpre13gfExwFZrrTur/GRgm1vBRER8aMeugzw/axX2m/30SmvJQ7f3IC4m0texUoDtVQ+6e9G2D/A28Ki1dqYx5mqg1VkPiQe+rzImGhhurX3OdchB5R8Kt5WWHq7VR5zj4qIoKTlU43GBTHMODpqz/2kY4uDXd6Xz8fJveefzLTz0P58w+NoOXJXeGqfDUavfWds5O50OYmPP/+ngard0jDGJwBxgiLV2putwfuVdpoMxJgQYAlS9YHsYGGWM6e26/TAwu4b5RUT8ntPpoG9mIk+O6E1KfBNeWWD502sr2b3Pv5qxuXPRdiQQATxrjFlljFkF5Lj+vQ1sADYCbwEYY/KMMbdYa09R+VbOl4wxhUAGMMrjMxAR8RMtmkYy8q50cvqn8s2ew4x9uYD5+d9wqsI/2jO4vYfvZcnANm3puE9zDg6ac+DYf+gE0xdaVm7aS3KrKIYNSCOxhXvN2DywpXPOPXy1VhARqQMxUQ14+Cfd+PmtXdl38DhPTl3K7M+3crLcd6v9wPqYmIhIAHE4HGSmtiCtbWUztve/2s7yohKG9U+lfZtor+fRCl9EpI41jgzjgZs78+igHhwvK+f3ry7n9Y83caLMu83YVPBFRLyke/tYJo7ozTWXtOGjZTsZMzmfDdv3ee35VfBFRLwoskEo9/Y1/GZIT0KcDp6ZuYopHxZy9HiNPqZUKyr4IiI+YJJimDA8iwGXtuXLtbsYnZfPyqKSOn1OFXwRER8JDwvhjmvak3tfBk0ahvP8O2t5ac46DtdRMzYVfBERH0tu1YQx9/XiJ1e1Y+WmEr5eW1z9oFrQ2zJFRPxAaIiTmy5P5sZeicS3asK+fUc8/hxa4YuI+JEG4SGEhNRNaVbBFxEJEir4IiJBQgVfRCRIqOCLiAQJFXwRkSChgi8iEiT89X34IVDZzL+2LmZsoNKcg4PmHBxqM+ezxoSc635//carK4DFvg4hIhKgrgS+qHrQXwt+AyATKAa82zBaRCRwhQDxwFLgRNU7/bXgi4iIh+mirYhIkFDBFxEJEir4IiJBQgVfRCRIqOCLiAQJFXwRkSChgi8iEiT8tbWCW4wxQ4BcIBx4zlr7QpX704FJQDTwOfAza22514N6kBtz/jEwAXAA24Bh1tr9Xg/qQdXN+azHDQT+Zq1N8Wa+uuDGeTbAP4AYYBdwV30/z8aYS6iccziwE7jHWvuD14N6kDGmCfAVcJO1dnuV+zxevwJ2hW+MaQP8N5VtGHoADxpjOld52HTgl9baTlQWwAe8m9Kzqpuz63+el4CB1toewBpgvA+ieoyb5xljTEvgGSrPc0Bz4zw7gPeAp13neSXwhC+yeoqb5/n/AWNdc7bASO+m9CxjTG8q2x90Os9DPF6/ArbgAzcAn1pr91lrjwBvAXecudMY0xaItNYucR2aCgzyekrPuuCcgTDgIWvtd67ba4AkL2f0tOrmfEYela9s6oPq5nwJcMRaO991+/fAOV/1BBB3znMI0MT1c0PgmBfz1YUHgF8A31e9o67qVyBv6bSmstfOGcVAVjX3J3ghV1264JyttaXAHABjTCSVq77nvRmwDlR3njHGPAKsAJZQP1Q35w7ALmPMNKAnsBb4pffi1YlqzzPwGPCRMeYvwBGgt5ey1Qlr7f0Albtz/6FO6lcgr/DP9dK9ogb3ByK35mSMiQY+BFZba6fVeaq6dcE5G2O6ArcDE72WqO5Vd55DgWuA56213YGtwLNeyFWXqjvPkcBk4HprbTzwIvCKl7L5Qp3Ur0Au+N8Brc66Hc+/vzSq7v5AVO2cjDHxVLaWXg3c771odaa6OQ9yHVtG5R+51saYQG+tXd2cdwGbrLXLXLdf5z9Xw4Gmujl3BY5Zawtct/9B5R+9+qpO6lcgF/yPgeuNMXHGmIZUrvLO7Glird0BHDfG9HEdygbmeT+mR11wzsaYEOAD4A1r7aPW2vrQCrW68zzOWtvJWpsODAC+t9Ze6aOsnnLBOVP5ro44Y0wP1+2bgeVezuhp1c15M5Bo/m//48dUtgCul+qqfgVswXddmBwNfAasAl6z1hYYYz40xvRyPWwo8JwxphBoBPzVN2k9w40530Llnu4dxphVrn95Pox80dw8z/VKdXO21h4DbgMmGWPWA9cBj/su8cVzY877gRzgDWPMGmA4MMxngetIXdcv9cMXEQkSAbvCFxGRmlHBFxEJEir4IiJBQgVfRCRIqOCLiAQJFXwRkSChgi8iEiRU8EVEgsT/B2dwXzJy+Z1YAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 2/100 [02:02<1:39:39, 61.01s/it]"
     ]
    }
   ],
   "source": [
    "hidden_dim = 10\n",
    "\n",
    "model = nn.Sequential(nn.Linear(input_dim[0], 1),\n",
    "                      nn.???())\n",
    "\n",
    "criterion = nn.???()\n",
    "learning_rate = 1.0\n",
    "optimizer = optim.???(model.parameters(), lr=learning_rate)\n",
    "num_epochs = 100\n",
    "\n",
    "\n",
    "losses = []\n",
    "plt.ion()\n",
    "\n",
    "for _e in tqdm(range(num_epochs)):\n",
    "    optimizer.zero_grad()\n",
    "    predictions = ???\n",
    "    loss_this_epoch = ???\n",
    "    loss_this_epoch.???()\n",
    "    optimizer.???()\n",
    "    ##print([float(_pred) for _pred in predictions], list(map(int, Y_pt)), loss_this_epoch.data[0])\n",
    "    losses.append(loss_this_epoch.data.item())\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    plt.plot(losses)\n",
    "    plt.pause(0.05)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(X_mnist_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.array([np.argmax(_p) for _p in predictions.data.numpy()])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = np.array([np.argmax(_p) for _p in Y_mnist_test.data.numpy()])\n",
    "truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pred == truth).sum() / len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
