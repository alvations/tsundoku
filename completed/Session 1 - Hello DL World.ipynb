{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Library/Frameworks/Python.framework/Versions/3.6/bin/python3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Optional]: If you're using a Mac/Linux, you can check your environment with these commands:\n",
    "\n",
    "```\n",
    "!which pip3\n",
    "!which python3\n",
    "!ls -lah /usr/local/bin/python3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (19.3.1)\n",
      "Collecting torch==1.3.0\n",
      "  Using cached https://files.pythonhosted.org/packages/8d/87/4e42d7ab7cb1e5ee9f2f81d9c5955a7c558894f11c90898fdf838ea40327/torch-1.3.0-cp36-none-macosx_10_7_x86_64.whl\n",
      "Requirement already satisfied: numpy in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from torch==1.3.0) (1.17.4)\n",
      "\u001b[31mERROR: allennlp 0.9.0 requires pytorch-transformers==1.1.0, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: apes 1.0.0 requires transformers==2.3.0, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: opennmt-py 1.0.0 has requirement tqdm~=4.30.0, but you'll have tqdm 4.41.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: onmt 1.0.0 has requirement torch==1.3.1, but you'll have torch 1.3.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: onmt 1.0.0 has requirement tqdm==4.38.0, but you'll have tqdm 4.41.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: apes 1.0.0 has requirement sacremoses==0.0.35, but you'll have sacremoses 0.0.38 which is incompatible.\u001b[0m\n",
      "Installing collected packages: torch\n",
      "  Found existing installation: torch 1.3.1\n",
      "    Uninstalling torch-1.3.1:\n",
      "      Successfully uninstalled torch-1.3.1\n",
      "Successfully installed torch-1.3.0\n",
      "Requirement already satisfied: seaborn in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (0.9.0)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from seaborn) (1.2.1)\n",
      "Requirement already satisfied: matplotlib>=1.4.3 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from seaborn) (3.1.1)\n",
      "Requirement already satisfied: numpy>=1.9.3 in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from seaborn) (1.17.4)\n",
      "Requirement already satisfied: pandas>=0.15.2 in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from seaborn) (0.25.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (2.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from matplotlib>=1.4.3->seaborn) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from pandas>=0.15.2->seaborn) (2019.2)\n",
      "Requirement already satisfied: six in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from cycler>=0.10->matplotlib>=1.4.3->seaborn) (1.13.0)\n",
      "Requirement already satisfied: setuptools in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn) (41.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -U pip\n",
    "!pip3 install torch==1.3.0\n",
    "!pip3 install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython candies...\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style> table {float:left} </style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style> table {float:left} </style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron\n",
    "=====\n",
    "\n",
    "**Perceptron** algorithm is a:\n",
    "\n",
    "> \"*system that depends on **probabilistic** rather than deterministic principles for its operation, gains its reliability from the **properties of statistical measurements obtain from a large population of elements***\"\n",
    "> \\- Frank Rosenblatt (1957)\n",
    "\n",
    "Then the news:\n",
    "\n",
    "> \"*[Perceptron is an] **embryo of an electronic computer** that [the Navy] expects will be **able to walk, talk, see, write, reproduce itself and be conscious of its existence.***\"\n",
    "> \\- The New York Times (1958)\n",
    "\n",
    "News quote cite from Olazaran (1996) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron in Bullets\n",
    "----\n",
    "\n",
    " - Perceptron learns to classify any linearly separable set of inputs. \n",
    " - Some nice graphics for perceptron with Go https://appliedgo.net/perceptron/  \n",
    "\n",
    "If you've got some spare time: \n",
    "\n",
    " - There's a whole book just on perceptron: https://mitpress.mit.edu/books/perceptrons\n",
    " - For watercooler gossips on perceptron in the early days, read [Olazaran (1996)](https://pdfs.semanticscholar.org/f3b6/e5ef511b471ff508959f660c94036b434277.pdf?_ga=2.57343906.929185581.1517539221-1505787125.1517539221)\n",
    " \n",
    " \n",
    "Perceptron in Math\n",
    "----\n",
    "\n",
    "Given a set of inputs $x$, the perceptron \n",
    "\n",
    " - learns $w$ vector to map the inputs to a real-value output between $[0,1]$\n",
    " - through the summation of the dot product of the $w·x$ with a transformation function\n",
    " \n",
    " \n",
    "Perceptron in Picture\n",
    "----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://ibin.co/4TyMU8AdpV4J.png\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Image(url=\"perceptron.png\", width=500)\n",
    "Image(url=\"https://ibin.co/4TyMU8AdpV4J.png\", width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(**Note:** Usually, we use $x_1$ as the bias and fix the input to 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron as a Workflow Diagram\n",
    "----\n",
    "\n",
    "If you're familiar with [mermaid flowchart](https://mermaidjs.github.io)\n",
    "\n",
    "```\n",
    ".. mermaid::\n",
    "\n",
    "    graph LR\n",
    "       subgraph Input\n",
    "          x_1\n",
    "          x_i \n",
    "          x_n\n",
    "       end\n",
    "       subgraph Perceptron\n",
    "            n1((s)) --> n2((\"f(s)\"))\n",
    "        end\n",
    "        x_1 --> |w_1| n1\n",
    "        x_i --> |w_i| n1\n",
    "        x_n --> |w_n| n1\n",
    "        n2 --> y[\"[0,1]\"]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://svgshare.com/i/AbJ.svg\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Image(url=\"perceptron-mermaid.svg\", width=500)\n",
    "Image(url=\"https://svgshare.com/i/AbJ.svg\", width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization Process\n",
    "====\n",
    "\n",
    "To learn the weights, $w$, we use an **optimizer** to find the best-fit (optimal) values for $w$ such that the inputs correct maps to the outputs.\n",
    "\n",
    "Typically, process performs the following 4 steps iteratively.\n",
    "\n",
    "### **Initialization**\n",
    "\n",
    " - **Step 1**: Initialize weights vector\n",
    " \n",
    "### **Forward Propagation**\n",
    "\n",
    " \n",
    " - **Step 2a**: Multiply the weights vector with the inputs, sum the products, i.e. `s`\n",
    " - **Step 2b**: Put the sum through the sigmoid, i.e. `f()`\n",
    " \n",
    "### **Back Propagation**\n",
    " \n",
    " \n",
    " - **Step 3a**: Compute the errors, i.e. difference between expected output and predictions\n",
    " - **Step 3b**: Multiply the error with the **derivatives** to get the delta\n",
    " - **Step 3c**: Multiply the delta vector with the inputs, sum the product\n",
    " \n",
    "### **Optimizer takes a step**\n",
    "\n",
    " - **Step 4**: Multiply the learning rate with the output of Step 3c.\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x): # Returns values that sums to one.\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(sx): \n",
    "    # See https://math.stackexchange.com/a/1225116\n",
    "    # Hint: let sx = sigmoid(x)\n",
    "    return sx * (1 - sx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92414182, 0.57932425, 0.19466158])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(np.array([2.5, 0.32, -1.42]))             # [out]: array([0.92414182, 0.57932425, 0.19466158])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.75  ,  0.2176, -3.4364])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_derivative(np.array([2.5, 0.32, -1.42]))  # [out]: array([0.07010372, 0.24370766, 0.15676845])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(predicted, truth):\n",
    "    return np.abs(truth - predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1, 0.2, 0.2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold = np.array([0.5, 1.2, 9.8])\n",
    "pred = np.array([0.6, 1.0, 10.0])\n",
    "cost(pred, gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.8,  2.8, 89.2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold = np.array([0.5, 1.2, 9.8])\n",
    "pred = np.array([9.3, 4.0, 99.0])\n",
    "cost(pred, gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representing OR Boolean\n",
    "---\n",
    "\n",
    "Lets consider the problem of the OR boolean and apply the perceptron with simple gradient descent. \n",
    "\n",
    "| x2 | x3 | y | \n",
    "|:--:|:--:|:--:|\n",
    "| 0 | 0 | 0 |\n",
    "| 0 | 1 | 1 | \n",
    "| 1 | 0 | 1 | \n",
    "| 1 | 1 | 1 | \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = or_input = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "Y = or_output = np.array([[0,1,1,1]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "or_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "or_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the shape of the weight vector.\n",
    "num_data, input_dim = or_input.shape\n",
    "# Define the shape of the output vector. \n",
    "output_dim = len(or_output.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs\n",
      "======\n",
      "no. of rows = 4\n",
      "no. of cols = 2\n",
      "\n",
      "\n",
      "Outputs\n",
      "=======\n",
      "no. of cols = 1\n"
     ]
    }
   ],
   "source": [
    "print('Inputs\\n======')\n",
    "print('no. of rows =', num_data) \n",
    "print('no. of cols =', input_dim)\n",
    "print('\\n')\n",
    "print('Outputs\\n=======')\n",
    "print('no. of cols =', output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5488135 ],\n",
       "       [0.71518937]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize weights between the input layers and the perceptron\n",
    "W = np.random.random((input_dim, output_dim))\n",
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2a: Multiply the weights vector with the inputs, sum the products\n",
    "====\n",
    "\n",
    "To get the output of step 2a, \n",
    "\n",
    " - Itrate through each row of the data, `X`\n",
    " - For each column in each row, find the product of the value and the respective weights\n",
    " - For each row, compute the sum of the products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.        ]\n",
      " [0.71518937]\n",
      " [0.5488135 ]\n",
      " [1.26400287]]\n"
     ]
    }
   ],
   "source": [
    "# If we write it imperatively:\n",
    "summation = []\n",
    "for row in X:\n",
    "    sum_wx = 0\n",
    "    for feature, weight in zip(row, W):\n",
    "        sum_wx += feature * weight\n",
    "    summation.append(sum_wx)\n",
    "print(np.array(summation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.71518937],\n",
       "       [0.5488135 ],\n",
       "       [1.26400287]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we vectorize the process and use numpy.\n",
    "np.dot(X, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Single-Layer Model\n",
    "====\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10000 # No. of times to iterate.\n",
    "learning_rate = 0.03 # How large a step to take per iteration.\n",
    "\n",
    "# Lets standardize and call our inputs X and outputs Y\n",
    "X = or_input\n",
    "Y = or_output\n",
    "\n",
    "for _ in range(num_epochs):\n",
    "    layer0 = X\n",
    "\n",
    "    # Step 2a: Multiply the weights vector with the inputs, sum the products, i.e. s\n",
    "    # Step 2b: Put the sum through the sigmoid, i.e. f()\n",
    "    # Inside the perceptron, Step 2. \n",
    "    layer1 = sigmoid(np.dot(X, W))\n",
    "\n",
    "    # Back propagation.\n",
    "    # Step 3a: Compute the errors, i.e. difference between expected output and predictions\n",
    "    # How much did we miss?\n",
    "    layer1_error = cost(layer1, Y)\n",
    "\n",
    "    # Step 3b: Multiply the error with the derivatives to get the delta\n",
    "    # multiply how much we missed by the slope of the sigmoid at the values in layer1\n",
    "    layer1_delta = layer1_error * sigmoid_derivative(layer1)\n",
    "\n",
    "    # Step 3c: Multiply the delta vector with the inputs, sum the product (use np.dot)\n",
    "    # Step 4: Multiply the learning rate with the output of Step 3c.\n",
    "    W +=  learning_rate * np.dot(layer0.T, layer1_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       ],\n",
       "       [0.95643415],\n",
       "       [0.95623017],\n",
       "       [0.99791935]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expected output.\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [1], [1], [1]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On the training data\n",
    "[[int(prediction > 0.5)] for prediction in layer1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try the XOR Boolean\n",
    "---\n",
    "\n",
    "Lets consider the problem of the OR boolean and apply the perceptron with simple gradient descent. \n",
    "\n",
    "| x2 | x3 | y | \n",
    "|:--:|:--:|:--:|\n",
    "| 0 | 0 | 0 |\n",
    "| 0 | 1 | 1 | \n",
    "| 1 | 0 | 1 | \n",
    "| 1 | 1 | 0 | \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = xor_input = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "Y = xor_output = np.array([[0,1,1,0]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xor_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xor_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10000 # No. of times to iterate.\n",
    "learning_rate = 0.003 # How large a step to take per iteration.\n",
    "\n",
    "# Lets drop the last row of data and use that as unseen test.\n",
    "X = xor_input\n",
    "Y = xor_output\n",
    "\n",
    "# Define the shape of the weight vector.\n",
    "num_data, input_dim = X.shape\n",
    "# Define the shape of the output vector. \n",
    "output_dim = len(Y.T)\n",
    "# Initialize weights between the input layers and the perceptron\n",
    "W = np.random.random((input_dim, output_dim))\n",
    "\n",
    "for _ in range(num_epochs):\n",
    "    layer0 = X\n",
    "    # Forward propagation.\n",
    "    # Inside the perceptron, Step 2. \n",
    "    layer1 = sigmoid(np.dot(X, W))\n",
    "\n",
    "    # How much did we miss?\n",
    "    layer1_error = cost(layer1, Y)\n",
    "\n",
    "    # Back propagation.\n",
    "    # multiply how much we missed by the slope of the sigmoid at the values in layer1\n",
    "    layer1_delta = sigmoid_derivative(layer1) * layer1_error\n",
    "\n",
    "    # update weights\n",
    "    W +=  learning_rate * np.dot(layer0.T, layer1_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expected output.\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 1]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On the training data\n",
    "[int(prediction > 0.5) for prediction in layer1] # All correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can't represent XOR with simple perceptron !!!\n",
    "====\n",
    "\n",
    "No matter how you change the hyperparameters or data, the XOR function can't be represented by a single perceptron layer.\n",
    " \n",
    "There's no way you can get all four data points to get the correct outputs for the XOR boolean operation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solving XOR (Add more layers)\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "def sigmoid(x): # Returns values that sums to one.\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(sx):\n",
    "    # See https://math.stackexchange.com/a/1225116\n",
    "    return sx * (1 - sx)\n",
    "\n",
    "# Cost functions.\n",
    "def cost(predicted, truth):\n",
    "    return truth - predicted\n",
    "\n",
    "xor_input = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "xor_output = np.array([[0,1,1,0]]).T\n",
    "\n",
    "# Define the shape of the weight vector.\n",
    "num_data, input_dim = X.shape\n",
    "# Lets set the dimensions for the intermediate layer.\n",
    "hidden_dim = 5\n",
    "# Initialize weights between the input layers and the hidden layer.\n",
    "W1 = np.random.random((input_dim, hidden_dim))\n",
    "\n",
    "# Define the shape of the output vector. \n",
    "output_dim = len(Y.T)\n",
    "# Initialize weights between the hidden layers and the output layer.\n",
    "W2 = np.random.random((hidden_dim, output_dim))\n",
    "\n",
    "# Initialize weigh\n",
    "num_epochs = 10000\n",
    "learning_rate = 0.03\n",
    "\n",
    "for epoch_n in range(num_epochs):\n",
    "    layer0 = X\n",
    "    # Forward propagation.\n",
    "    \n",
    "    # Inside the perceptron, Step 2. \n",
    "    layer1 = sigmoid(np.dot(layer0, W1))\n",
    "    layer2 = sigmoid(np.dot(layer1, W2))\n",
    "\n",
    "    # Back propagation (Y -> layer2)\n",
    "    \n",
    "    # How much did we miss in the predictions?\n",
    "    layer2_error = cost(layer2, Y)\n",
    "    # In what direction is the target value?\n",
    "    # Were we really close? If so, don't change too much.\n",
    "    layer2_delta = layer2_error * sigmoid_derivative(layer2)\n",
    "\n",
    "    \n",
    "    # Back propagation (layer2 -> layer1)\n",
    "    # How much did each layer1 value contribute to the layer2 error (according to the weights)?\n",
    "    layer1_error = np.dot(layer2_delta, W2.T)\n",
    "    layer1_delta = layer1_error * sigmoid_derivative(layer1)\n",
    "    \n",
    "    # update weights\n",
    "    W2 +=  learning_rate * np.dot(layer1.T, layer2_delta)\n",
    "    W1 +=  learning_rate * np.dot(layer0.T, layer1_delta)\n",
    "    ##print(epoch_n, list((layer2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training input.\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expected output.\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31284349],\n",
       "       [0.6213127 ],\n",
       "       [0.62323891],\n",
       "       [0.46427804]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2 # Our output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 0]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On the training data\n",
    "[int(prediction > 0.5) for prediction in layer2] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try adding another layer\n",
    "====\n",
    "\n",
    "Use the same process:\n",
    "    \n",
    "  1. Initialize\n",
    "  2. Forward Propagate\n",
    "  3. Back Propagate \n",
    "  4. Update (aka step)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "def sigmoid(x): # Returns values that sums to one.\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(sx):\n",
    "    # See https://math.stackexchange.com/a/1225116\n",
    "    return sx * (1 - sx)\n",
    "\n",
    "# Cost functions.\n",
    "def cost(predicted, truth):\n",
    "    return truth - predicted\n",
    "\n",
    "xor_input = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "xor_output = np.array([[0,1,1,0]]).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the shape of the weight vector.\n",
    "num_data, input_dim = X.shape\n",
    "# Lets set the dimensions for the intermediate layer.\n",
    "layer0to1_hidden_dim = 5\n",
    "layer1to2_hidden_dim = 5\n",
    "\n",
    "# Initialize weights between the input layers 0 ->  layer 1\n",
    "W1 = np.random.random((input_dim, layer0to1_hidden_dim))\n",
    "\n",
    "# Initialize weights between the layer 1 -> layer 2\n",
    "W2 = np.random.random((layer0to1_hidden_dim, layer1to2_hidden_dim))\n",
    "\n",
    "# Define the shape of the output vector. \n",
    "output_dim = len(Y.T)\n",
    "# Initialize weights between the layer 2 -> layer 3\n",
    "W3 = np.random.random((layer1to2_hidden_dim, output_dim))\n",
    "\n",
    "# Initialize weigh\n",
    "num_epochs = 10000\n",
    "learning_rate = 1.0\n",
    "\n",
    "for epoch_n in range(num_epochs):\n",
    "    layer0 = X\n",
    "    # Forward propagation.\n",
    "    \n",
    "    # Inside the perceptron, Step 2. \n",
    "    layer1 = sigmoid(np.dot(layer0, W1))\n",
    "    layer2 = sigmoid(np.dot(layer1, W2))\n",
    "    layer3 = sigmoid(np.dot(layer2, W3))\n",
    "\n",
    "    # Back propagation (Y -> layer2)\n",
    "    # How much did we miss in the predictions?\n",
    "    layer3_error = cost(layer3, Y)\n",
    "    # In what direction is the target value?\n",
    "    # Were we really close? If so, don't change too much.\n",
    "    layer3_delta = layer3_error * sigmoid_derivative(layer3)\n",
    "\n",
    "    # Back propagation (layer2 -> layer1)\n",
    "    # How much did each layer1 value contribute to the layer3 error (according to the weights)?\n",
    "    layer2_error = np.dot(layer3_delta, W3.T)\n",
    "    layer2_delta = layer3_error * sigmoid_derivative(layer2)\n",
    "    \n",
    "    # Back propagation (layer2 -> layer1)\n",
    "    # How much did each layer1 value contribute to the layer2 error (according to the weights)?\n",
    "    layer1_error = np.dot(layer2_delta, W2.T)\n",
    "    layer1_delta = layer1_error * sigmoid_derivative(layer1)\n",
    "    \n",
    "    # update weights\n",
    "    W3 +=  learning_rate * np.dot(layer2.T, layer3_delta)\n",
    "    W2 +=  learning_rate * np.dot(layer1.T, layer2_delta)\n",
    "    W1 +=  learning_rate * np.dot(layer0.T, layer1_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50039537],\n",
       "       [0.50000003],\n",
       "       [0.9929507 ],\n",
       "       [0.50001378]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On the training data\n",
    "[int(prediction > 0.5) for prediction in layer3] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, lets do it with PyTorch \n",
    "\n",
    "First lets try a single perceptron and see that we can't train a model that can represent XOR. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch import FloatTensor\n",
    "from torch import optim\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set(rc={'figure.figsize':(15, 10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X # Original XOR X input in numpy array data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y # Original XOR Y output in numpy array data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]])\n",
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "device = 'gpu' if torch.cuda.is_available()  else 'cpu'\n",
    "# Converting the X to PyTorch-able data structure.\n",
    "X_pt = torch.tensor(X).float()\n",
    "X_pt = X_pt.to(device)\n",
    "# Converting the Y to PyTorch-able data structure.\n",
    "Y_pt = torch.tensor(Y, requires_grad=False).float()\n",
    "Y_pt = Y_pt.to(device)\n",
    "print(X_pt)\n",
    "print(Y_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs Dim: 2\n",
      "Output Dim: 1\n"
     ]
    }
   ],
   "source": [
    "# Use tensor.shape to get the shape of the matrix/tensor.\n",
    "num_data, input_dim = X_pt.shape\n",
    "print('Inputs Dim:', input_dim)\n",
    "\n",
    "num_data, output_dim = Y_pt.shape\n",
    "print('Output Dim:', output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=1, bias=True)\n",
       "  (1): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use Sequential to define a simple feed-forward network.\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim), # Use nn.Linear to get our simple perceptron\n",
    "            nn.Sigmoid()                      # Use nn.Sigmoid to get our sigmoid non-linearity\n",
    "        )\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember we define as: cost = truth - predicted\n",
    "# If we take the absolute of cost, i.e.: cost = |truth - predicted|\n",
    "# we get the L1 loss function. \n",
    "criterion = nn.L1Loss() \n",
    "learning_rate = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The simple weights/parameters update processes we did before\n",
    "# is call the gradient descent. SGD is the sochastic variant of\n",
    "# gradient descent. \n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(**Note**: Personally, I strongely encourage you to go through the [University of Washington course of machine learning regression](https://www.coursera.org/learn/ml-regression) to better understand the fundamentals of (i) ***gradient***, (ii) ***loss*** and (iii) ***optimizer***. But given that you know how to code it, the process of more complex variants of gradient/loss computation and optimizer's step is easy to grasp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a PyTorch model\n",
    "\n",
    "To train a model using PyTorch, we simply iterate through the no. of epochs and imperatively state the computations we want to perform. \n",
    "\n",
    "## Remember the steps?\n",
    "\n",
    " 1. Initialize \n",
    " 2. Forward Propagation\n",
    " 3. Backward Propagation\n",
    " 4. Update Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:05<00:00, 1932.42it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Initialization. \n",
    "# Note: When using PyTorch a lot of the manual weights\n",
    "#       initialization is done automatically when we define\n",
    "#       the model (aka architecture)\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim), \n",
    "            nn.Sigmoid())\n",
    "criterion = nn.MSELoss() \n",
    "learning_rate = 1.0\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "num_epochs = 10000\n",
    "\n",
    "losses = []\n",
    "\n",
    "for i in tqdm(range(num_epochs)):\n",
    "    # Reset the gradient after every epoch. \n",
    "    optimizer.zero_grad() \n",
    "    # Step 2: Foward Propagation\n",
    "    predictions = model(X_pt)\n",
    "    \n",
    "    # Step 3: Back Propagation \n",
    "    # Calculate the cost between the predictions and the truth.\n",
    "    loss_this_epoch = criterion(predictions, Y_pt)\n",
    "    # Note: The neat thing about PyTorch is it does the \n",
    "    #       auto-gradient computation, no more manually defining\n",
    "    #       derivative of functions and manually propagating\n",
    "    #       the errors layer by layer.\n",
    "    loss_this_epoch.backward()\n",
    "    \n",
    "    # Step 4: Optimizer take a step. \n",
    "    # Note: Previously, we have to manually update the \n",
    "    #       weights of each layer individually according to the\n",
    "    #       learning rate and the layer delta. \n",
    "    #       PyTorch does that automatically =)\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Log the loss value as we proceed through the epochs.\n",
    "    losses.append(loss_this_epoch.data.item())\n",
    "    \n",
    "# Visualize the losses\n",
    "plt.plot(losses)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\t [0, 0]\n",
      "Pred:\t 0\n",
      "Ouput:\t 0\n",
      "######\n",
      "Input:\t [0, 1]\n",
      "Pred:\t 0\n",
      "Ouput:\t 1\n",
      "######\n",
      "Input:\t [1, 0]\n",
      "Pred:\t 0\n",
      "Ouput:\t 1\n",
      "######\n",
      "Input:\t [1, 1]\n",
      "Pred:\t 0\n",
      "Ouput:\t 0\n",
      "######\n"
     ]
    }
   ],
   "source": [
    "for _x, _y in zip(X_pt, Y_pt):\n",
    "    prediction = model(_x)\n",
    "    print('Input:\\t', list(map(int, _x)))\n",
    "    print('Pred:\\t', int(prediction))\n",
    "    print('Ouput:\\t', int(_y))\n",
    "    print('######')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, try again with 2 layers using PyTorch\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:02<00:00, 1836.28it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.95 s, sys: 133 ms, total: 3.09 s\n",
      "Wall time: 3.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hidden_dim = 5\n",
    "num_data, input_dim = X_pt.shape\n",
    "num_data, output_dim = Y_pt.shape\n",
    "\n",
    "model = nn.Sequential(nn.Linear(input_dim, hidden_dim),\n",
    "                      nn.Sigmoid(), \n",
    "                      nn.Linear(hidden_dim, output_dim),\n",
    "                      nn.Sigmoid())\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 0.3\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "num_epochs = 5000\n",
    "\n",
    "losses = []\n",
    "\n",
    "for _ in tqdm(range(num_epochs)):\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(X_pt)\n",
    "    loss_this_epoch = criterion(predictions, Y_pt)\n",
    "    loss_this_epoch.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss_this_epoch.data.item())\n",
    "    ##print([float(_pred) for _pred in predictions], list(map(int, Y_pt)), loss_this_epoch.data[0])\n",
    "    \n",
    "# Visualize the losses\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\t [0, 0]\n",
      "Pred:\t 0\n",
      "Ouput:\t 0\n",
      "######\n",
      "Input:\t [0, 1]\n",
      "Pred:\t 1\n",
      "Ouput:\t 1\n",
      "######\n",
      "Input:\t [1, 0]\n",
      "Pred:\t 1\n",
      "Ouput:\t 1\n",
      "######\n",
      "Input:\t [1, 1]\n",
      "Pred:\t 0\n",
      "Ouput:\t 0\n",
      "######\n"
     ]
    }
   ],
   "source": [
    "for _x, _y in zip(X_pt, Y_pt):\n",
    "    prediction = model(_x)\n",
    "    print('Input:\\t', list(map(int, _x)))\n",
    "    print('Pred:\\t', int(prediction > 0.5))\n",
    "    print('Ouput:\\t', int(_y))\n",
    "    print('######')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST: The \"Hello World\" of Neural Nets\n",
    "====\n",
    "\n",
    "Like any deep learning class, we ***must*** do the MNIST. \n",
    "\n",
    "The MNIST dataset is \n",
    "\n",
    " - is made up of handwritten digits \n",
    " - 60,000 examples training set\n",
    " - 10,000 examples test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (0.2.2.post3)\r\n",
      "Requirement already satisfied: six in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from torchvision) (1.13.0)\r\n",
      "Requirement already satisfied: numpy in /Users/liling.tan/Library/Python/3.6/lib/python/site-packages (from torchvision) (1.17.4)\r\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from torchvision) (1.3.0)\r\n",
      "Requirement already satisfied: pillow>=4.1.1 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from torchvision) (5.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "# We're going to install tensorflow here because their dataset access is simpler =)\n",
    "!pip3 install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = datasets.MNIST('../data', train=True, download=True, \n",
    "                             transform=transforms.Compose([\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "mnist_test = datasets.MNIST('../data', train=False, download=True, \n",
    "                             transform=transforms.Compose([\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.1307,), (0.3081,))\n",
    "                             ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization Candies\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_image(mnist_x_vector, mnist_y_vector):\n",
    "    pixels = mnist_x_vector.reshape((28, 28))\n",
    "    label = np.where(mnist_y_vector == 1)[0]\n",
    "    plt.title('Label is {}'.format(label))\n",
    "    plt.imshow(pixels, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP0AAAEJCAYAAABfQSFHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAT4UlEQVR4nO3dfZAU9Z3H8fe4QSQoJpaUboLscId8NZEiosRgQLkK+GwUnziQGKwI6GmhVoiai7kFkpPCukOND2WVdyTepUSvRPgDxEPFu4BQxrsEvah8C5VdnjZnLpJC0Swoc3/07DIz7vbMzvQ8wO/zqqKqu7/TPd9t9jPd093bncpkMohIOI6odwMiUlsKvUhgFHqRwCj0IoFR6EUCo9CLBOZz9W5AKmNmaeB37n50H+fLAIPd/f/6MM8vsu/1DwXTFwBvu/u/lLicecDNwEbgj8CFwNPufkupvUj5FHqpmLv/XRmzPdUV8uyHwPGJNiW9UugPY2Y2AngYOBr4ErAJmOLuf86+5O/NbAzR17y73X1ldr7vAX+Tnf5H4BZ33xzzPr8guwdgZvOBycC+7Lwz3L2jGj+flEff6Q9vM4HH3X0sMBwYBlycU3/X3UcD04HHzWywmZ0LfBcY7+6nA/cCz5TyZmZ2EnAbMMbdzwTWAGcl9tNIIrSlP7zdCUwyszuAEURb+9zv/o8CuPvvzOxNYCwwjugDYoOZdb3uODM7roT32wm8BvzGzFYDq939xUR+EkmMtvSHt6XALKAduA/4DZDKqX+aM5wC9gNNwL+6+9fc/WvAaOBMYHexN3P3A8C5wAyiXfv7zOyByn8MSZJCf3g7H1jg7k8BGaJd7aac+gwAMxsNnAy8QrRLPtXMmrOvuREoaWttZqOA3wFvuftCog+aUZX/GJIk7d4fHgaa2YcF08YCfwssN7P3gY+A/yTade/yF2b2W6IPhL929/eBfzezRcDzZnYA2ANc4e6ZnN39Hrn7a2b2b8B/Zfv5GJiTwM8nCUrpT2ul1rpO0RWestN5+trQll7qZYqZDSXn4pw69xMMbelFAqMDeSKBUehFAlOP7/T9gTFAB/nniUUkGU1AM/Aq0FlYrCj0ZjYNuBs4ErjP3R8uYbYxwLpK3ldESjIeWF84sewDeWb25ewCzyD6NNkATHX3N4vM+pfA2+PGjWPHjh0AtLW1kU6ny+qj2hq1t0btC9RbuZLqbciQIaxfvx6iazLeKaxXsqWfCKzNXtCBmT0NXAUsKDLfpwA7duygvb29e2LucKNp1N4atS9Qb+VKuLcevz5XciDvS0Tfy7t0AEMqWJ6I1EAlW/pUD9MOlDpzW1tb3ngjXy/QqL01al+g3spVi94qCf1OogMFXZqBXaXOnE6nu3dlMpkMqVRPnyH116i9NWpfoN7KlVRvLS0tn9mo5qok9C8A88xsMLAXuJLozzhFpIGV/Z3e3XcCPwJeIroN0xPu/uukGhOR6qjoPL27PwE8kVAvIlIDugxXJDAKvUhgFHqRwCj0IoFR6EUCo9CLBEahFwmMQi8SGIVeJDAKvUhgFHqRwCj0IoFR6EUCo9CLBEahFwmMQi8SGIVeJDAKvUhgFHqRwCj0IoFR6EUCo9CLBEahFwmMQi8SGIVeJDAKvUhgFHqRwCj0IoFR6EUCU9FTa0W6HHPMMbHjRx99dK/zXnzxxbHLHjx4cGx98eLFsfXOzs7YemgqCr2ZrQVOAPZnJ81291cq7kpEqqbs0JtZCjgFGOrunyTXkohUUyXf6Q3IAKvN7DUzuyWhnkSkiioJ/ReBF4HLgW8BN5rZpES6EpGqSWUymUQWZGa3E+3q317kpWlgayJvKiJxhgFthRMr+U4/Dujv7i9mJ6U4eECvqHQ6TXt7OwCZTIZUKlVuK1XVqL01Wl+5R+v37NnDoEGD8uqNcvS+0dZbrqR6a2lpoa2trdd6JUfvvwAsMLOzgX7Ad4EbK1ieiNRA2aF395VmdhbwW6AJeNjdNybWmdRUOp2Ord95552x9bFjx+aNr1u3Lm/8tNNOK6uvUjQ3N8fW58yZU7X3PhRVdJ7e3X8M/DihXkSkBnQZrkhgFHqRwCj0IoFR6EUCo9CLBEZ/WnsYOeWUU3qt3XbbbbHzXnvttbH1AQMGxNYLLyoZOXJk3vj27dt7nfeDDz6IXfapp54aW7/mmmti64888kjeeO562rx5c+y8hyNt6UUCo9CLBEahFwmMQi8SGIVeJDAKvUhgFHqRwOg8fQM59thjY+uLFi3KG3/00UfzxqdMmdLrvIW3pE7ali1buofNLG8c4Pzzz+913n79+sUuu9i59OOPP75P9WKvP9xpSy8SGIVeJDAKvUhgFHqRwCj0IoFR6EUCo9CLBEbn6RvI5MmTY+s33HBD7Hg1vfPOO7H1SZMOPtFs27ZteeMQ//f0w4cPr6w56RNt6UUCo9CLBEahFwmMQi8SGIVeJDAKvUhgFHqRwOg8fQO5+uqrq7bstra22Pqrr74aWy/2qOrC8/Bx5+ULFbuvvSSrpNCb2SBgA3CJu7eZ2URgMTAAeMrd765ijyKSoKK792Z2FrAeGJEdHwAsAS4DTgXGmNmF1WxSRJJTynf6mcDNwK7s+NeBLe6+1d0/AX4JVG+/VEQSlcpkMiW90MzagAnAWOBid5+enT4RuMPdzyvxPdPA1j72KSJ9NwxoK5xYzoG8VA/TDvR1Iel0mvb2dgAymcxnHoDYKGrZ26pVq2LruTeXbGpq4tNPPy152dU+kLdt27bu4b6us0svvTS2vnz58pKX1ZMJEyZ0D69bt47x48d3j69fv76iZScpqd+1lpaW2P/vck7Z7QROzBlv5uCuv4g0uHK29K8AZmbDiXbTpxEd2BORQ0CfQ+/ufzazGcAy4CjgWeDphPsK0syZM2Prs2bN6h5ubW3lpz/9aV59zZo1vc779ttvxy77vffeK6HD6jjhhBPq9t4hKjn07p7OGX4RGFWNhkSkunQZrkhgFHqRwCj0IoFR6EUCo9CLBEZ/WttAdu2Kv8Zp3rx53cOtra1544eysWPH1ruFoGhLLxIYhV4kMAq9SGAUepHAKPQigVHoRQKj0IsERufpBYA5c+bE1gcOHNin5f3whz8s+bUjR47s07ILbdiwIba+cePG2PHQaEsvEhiFXiQwCr1IYBR6kcAo9CKBUehFAqPQiwRG5+kPIZ///Odjx7/yla/0Om9ra2vssi+66KLyGwOOOCJ/+3HPPffkjR840OeHIHUrdp+B66+/PrZe+CSgvjwZ6HCkLb1IYBR6kcAo9CKBUehFAqPQiwRGoRcJjEIvEhidp6+hfv36xdZPP/302PqyZcvyxt09b7y5ubnXeT/++OPYZRc7F17sb9AvuOCC7uFjjjmGDz74IK9eeE1BX3zuc/G/pldccUVs/YEHHsgbP/LII7uH9+3bV3Zfh6qSQ29mg4ANwCXu3mZmS4DxwN7sS+a7+/Iq9CgiCSop9GZ2FvAYMCJn8hjgHHfvqEZjIlIdpX6nnwncDOwCMLOBwFDgMTN73czmm5mOD4gcAlKZTKbkF5tZGzCB6MPiH4HZwIfASmCpuz9WwmLSwNa+tSkiZRgGtBVOLOtAnru/C0zuGjezB4HriL4ClCSdTtPe3g5AJpMhlUqV00rVJdlbkgfyhgwZwo4dO/LqlRzI+9Of/hRbr+eBvD/84Q+x9cWLF8fWcw/kdXZ20r9//+7xRjqQl9TvWktLC21tbb3Wy9olN7ORZnZlzqQUsL+cZYlIbZV7yi4F3G9ma4l272cBjyfWlYhUTbm796+b2ULgZaAfsMzdlyba2SEo9/xvT3J3gXvyzDPP9On9Cnfn58+f3+tr165dG7usl19+ObZ+3HHHxdZzlz9q1CjefffdvPppp50WO3+cwYMHx9YXLlwYW9+2bVve+OTJ3d9MWbFiRey8nZ2dRbo79PQp9O6ezhl+BHgk6YZEpLp0mk0kMAq9SGAUepHAKPQigVHoRQLTp8twE5IGth6qV+TFXVW3YMGC2GX94Ac/qKiX1atXdw9fcsklrFy5Mq/+ne98p9d5i11xV+y02LPPPhtbHz16dPfwEUcc8ZlbXsdd+XbvvffGLrvY6b7LLrsstp6rqakp7xbYL7zwQuzrFy1aFFvfvXt3ye/dk02bNnUPV+GKvB4vw9WWXiQwCr1IYBR6kcAo9CKBUehFAqPQiwRGoRcJjG6BXaCpqSl22k9+8pNe5507d27ssvfu3Rtbv+uuu2LrTz75ZPfw+++/z3XXXZdXjzsXf+aZZ8Yu+6GHHoqtF7urz5YtW7qHzSxvHOCmm27qdd6XXnopdtmDBg2KrZ999tmx9WuvvbZ7ePr06SxdevCvwL/97W/Hzvv888/H1ovZvn17bH3YsGEVLb8c2tKLBEahFwmMQi8SGIVeJDAKvUhgFHqRwCj0IoHRefoCs2bNip0Wdy7+o48+il327NmzY+tr1qyJrX/jG9+IHb/++ut7nffCCy+MXfaAAQNi68XuFfDzn/+8e3jbtm1MmjQpr17sfHWcPXv2xNafe+65kuvTp0/Pu+/A1KlTY+edNm1aCR327vbbb69o/mrQll4kMAq9SGAUepHAKPQigVHoRQKj0IsERqEXCUxJ9703s1bgmuzoKne/w8wmAouBAcBT7n53ie+ZpoHve9/R0ZE3fuKJJ/L73/++ezzu/vDFHmu8efPm2PrAgQNj68OHD+8eLrx/e6XmzZsXWy/2OOjcXhrp/7NQCL1VfN/7bLjPA04HvgacYWZTgSXAZcCpwBgzi7/6Q0QaQim79x3A9919n7vvB94CRgBb3H2ru38C/BK4uop9ikhCil6G6+5vdA2b2cnAFOBnRB8GXTqAIYl3JyKJK/lZdmb2VWAV0ArsBy5y9+nZ2kRgrrtfUMKi0sDWsroVkb7o8Tt9SX9wY2bfBJYBt7n7k2Z2LnBizkuagV196UYH8j5LB/KqL4Tecg7k9aho6M3sJGAFMMXd12YnvxKVbDjRVnsa0YE9EWlwpWzp5wJHAYvNrGvao8AMoq3/UcCzwNNV6K/mcrfq0Lctff/+/WOXPWrUqIp6y31c9KWXXvqZx0f/6le/6nXeFStWxC47bssAJLpXIfVVyoG8W4FbeylX9lssIjWnK/JEAqPQiwRGoRcJjEIvEhiFXiQwCr1IYHQL7ALnnHNO3viePXvypl1++eW9zjt69OjYZb/33nux9SVL4q9v2r17d/dwZ2cnV111VV593759sfOLgLb0IsFR6EUCo9CLBEahFwmMQi8SGIVeJDAKvUhgSr5dVoLSNPAtsAs1am+N2heot3I1zC2wReTwotCLBEahFwmMQi8SGIVeJDAKvUhgFHqRwCj0IoFR6EUCo9CLBEahFwmMQi8SGIVeJDAKvUhgFHqRwJR033szawWuyY6ucvc7zGwJMB7Ym50+392XV6FHEUlQ0dCb2UTgPOB0IAM8Z2aTgTHAOe7eUd0WRSRJpWzpO4Dvu/s+ADN7Cxia/feYmQ0FlhNt6Q9UrVMRSUTR0Lv7G13DZnYyMAUYB0wAZgMfAiuB7wGPVaVLEUlMyc+yM7OvAquAue7uwOSc2oPAdfQh9Nl7eHWrw736StaovTVqX6DeylWL3ko9kPdNYBlwm7s/aWYjgRHuviz7khSwvy9vrBtjVqZR+wL1Vq4q3BizR6UcyDsJWAFMcfe12ckp4H4zW0u0ez8LeLzibkWk6krZ0s8FjgIWm1nXtEeBhcDLQD9gmbsvrUqHIpKoUg7k3Qrc2kv5kWTbEZFq0xV5IoFR6EUCo9CLBEahFwmMQi8SGIVeJDAKvUhgFHqRwCj0IoFR6EUCo9CLBEahFwmMQi8SmJLvnJOgJoAhQ4bkTWxpaalDK6Vp1N4atS9Qb+VKorecbDX1VE/V4dZB44B1tX5TkQCNB9YXTqxH6PsT3T67A/i01m8uEoAmoBl4FegsLNYj9CJSRzqQJxIYhV4kMAq9SGAUepHAKPQigVHoRQKj0IsEph6X4XYzs2nA3cCRwH3u/nA9+8mVfWTXCRx8Rt9sd3+lji1hZoOADcAl7t5mZhOBxcAA4Cl3v7tB+lpCdDXY3uxL5rv78jr01Qpckx1d5e53NNA666m3mqy3ul2cY2ZfJrpE8Ayiq4Y2AFPd/c26NJTDzFLATmCou39S734AzOwsoqcCnwKMAP4XcOBcYDvRE4Xvd/fV9ewrG/r/Ac5z945a9lLQ10RgPvBXQAZ4DvgnYBH1X2c99fYQsIAarLd67t5PBNa6+/vuvhd4Griqjv3kMqL/jNVm9pqZ3VLvhoCZwM3Aruz414Et7r41+8H0S+DqevdlZgOBocBjZva6mc03s3r8nnUA33f3fe6+H3iL6MOyEdZZT70NpUbrrZ67918i+uG7dBD9IjeCLwIvAjcR7Qb+h5m5uz9fr4bc/QaAnIeI9rT+hlBjPfR1ArAWmE30ROOVwPeI9gZq2dcbXcNmdjIwBfgZjbHOeuptHDCBGqy3eoa+pwdxH6h5Fz1w943AxuzoXjP7Z+AioG6h70FDrj93fxeY3DVuZg8C11Hj0Oe8/1eJduPnEh2fsYKX1G2d5fbm7k6N1ls9d+93AifmjDdzcNe1rsxsnJl9K2dSioMH9BpFQ64/MxtpZlfmTKrbujOzbxLtsd3l7o/TQOussLdarrd6bulfAOaZ2WCio5VXArPq2E+uLwALzOxsoB/wXeDG+rb0Ga8AZmbDga3ANGBJfVsCol/W+7NnPz4k+j99vNZNmNlJwApgiruvzU5uiHXWS281W29129K7+07gR8BLwCbgCXf/db36yeXuK4l2u34L/DewJLvL3zDc/c/ADGAZ8CawmehgaF25++vAQuBlor42ufvSOrQyFzgKWGxmm8xsE9H6mkH911lPvZ1Njdab/p5eJDC6Ik8kMAq9SGAUepHAKPQigVHoRQKj0IsERqEXCYxCLxKY/wfxF08vn4INuwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fifth image and label.\n",
    "show_image(mnist_train.data[5], mnist_train.targets[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets apply what we learn about multi-layered perceptron with PyTorch and apply it to the MNIST data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mnist = mnist_train.data.float()\n",
    "Y_mnist = mnist_train.targets.float()\n",
    "\n",
    "X_mnist_test = mnist_test.data.float()\n",
    "Y_mnist_test = mnist_test.targets.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_mnist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of images: 60000\n",
      "Inputs Dim: [28, 28]\n",
      "Output Dim: []\n"
     ]
    }
   ],
   "source": [
    "# Use FloatTensor.shape to get the shape of the matrix/tensor.\n",
    "num_data, *input_dim = X_mnist.shape\n",
    "print('No. of images:', num_data)\n",
    "print('Inputs Dim:', input_dim)\n",
    "\n",
    "num_data, *output_dim = Y_mnist.shape\n",
    "num_test_data, *output_dim = Y_mnist_test.shape\n",
    "print('Output Dim:', output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the dimensions of the images.\n",
    "X_mnist = mnist_train.data.float().view(num_data, -1)\n",
    "Y_mnist = mnist_train.targets.float().unsqueeze(1)\n",
    "\n",
    "X_mnist_test = mnist_test.data.float().view(num_test_data, -1)\n",
    "Y_mnist_test = mnist_test.targets.float().unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of images: 60000\n",
      "Inputs Dim: [784]\n",
      "Output Dim: [1]\n"
     ]
    }
   ],
   "source": [
    "# Use FloatTensor.shape to get the shape of the matrix/tensor.\n",
    "num_data, *input_dim = X_mnist.shape\n",
    "print('No. of images:', num_data)\n",
    "print('Inputs Dim:', input_dim)\n",
    "\n",
    "num_data, *output_dim = Y_mnist.shape\n",
    "num_test_data, *output_dim = Y_mnist_test.shape\n",
    "print('Output Dim:', output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:04<00:00,  2.09it/s]\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = 500\n",
    "\n",
    "model = nn.Sequential(nn.Linear(784, 1),\n",
    "                      nn.Sigmoid())\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 1.0\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "losses = []\n",
    "plt.ion()\n",
    "\n",
    "for _e in tqdm(range(num_epochs)):\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(X_mnist)\n",
    "    loss_this_epoch = criterion(predictions, Y_mnist)\n",
    "    loss_this_epoch.backward()\n",
    "    optimizer.step()\n",
    "    ##print([float(_pred) for _pred in predictions], list(map(int, Y_pt)), loss_this_epoch.data[0])\n",
    "    losses.append(loss_this_epoch.data.item())\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    plt.plot(losses)\n",
    "    plt.pause(0.05)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        ...,\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model(X_mnist_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.array([np.argmax(_p) for _p in predictions.data.numpy()])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth = np.array([np.argmax(_p) for _p in Y_mnist_test.data.numpy()])\n",
    "truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pred == truth).sum() / len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
